<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hive on SoByte</title>
    <link>https://www.sobyte.net/tags/hive/</link>
    <description>Recent content in hive on SoByte</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 14 Jan 2022 10:35:25 +0800</lastBuildDate><atom:link href="https://www.sobyte.net/tags/hive/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Big Data Basics: HIVE</title>
      <link>https://www.sobyte.net/post/2022-01/hive/</link>
      <pubDate>Fri, 14 Jan 2022 10:35:25 +0800</pubDate>
      
      <guid>https://www.sobyte.net/post/2022-01/hive/</guid>
      <description>Hive Introduction Hive, implemented by Facebook and open source, is a data warehouse tool based on Hadoop. It maps structured data into a database table and provides HQL (Hive SQL) queries. The underlying data is stored on HDFS, and Hive essentially converts SQL statements into MapReduce tasks to run, making it easy for users unfamiliar with MapReduce to process and compute structured data on HDFS using HQL, suitable for offline</description>
    </item>
    
    <item>
      <title>Hive SQL CURRENT_DATE causes datediff error</title>
      <link>https://www.sobyte.net/post/2021-11/hive-sql-datediff-current_date/</link>
      <pubDate>Thu, 04 Nov 2021 14:27:46 +0800</pubDate>
      
      <guid>https://www.sobyte.net/post/2021-11/hive-sql-datediff-current_date/</guid>
      <description>The datediff function in Hive SQL returns the number of days between 2 dates. One of the more interesting pitfalls found during use is that
1 2 3 4 5 6 7 8  SELECTcustomer_id,COUNT(DISTINCTdate(createdate))-1ASfrequency,datediff(MAX(createdate),MIN(createdate))ASrecency,datediff(CURRENT_DATE,MIN(createdate))AST,CASEWHENCOUNT(DISTINCTcreatedate)-1=0THEN0ELSESUM(totaltakeoff)/COUNT(DISTINCTcreatedate)ENDASmonetary_valueFROMorderdb.orderdetail  Where createdate is a datetime type, the execution of SQL finds that there is data with recency&amp;gt;T. The following code is executed and the result also has problems.
1 2 3 4 5 6 7 8  SELECTcustomer_id,COUNT(DISTINCTdate(createdate))-1ASfrequency,datediff(to_date(MAX(createdate)),to_date(MIN(createdate)))ASrecency,datediff(CURRENT_DATE,to_date(MIN(createdate)))AST,CASEWHENCOUNT(DISTINCTcreatedate)-1=0THEN0ELSESUM(totaltakeoff)/COUNT(DISTINCTcreatedate)ENDASmonetary_valueFROMorderdb.</description>
    </item>
    
    <item>
      <title>JupyterLab HIVE Data Synchronization Process</title>
      <link>https://www.sobyte.net/post/2021-10/jupyterlab-hive/</link>
      <pubDate>Sat, 30 Oct 2021 13:48:06 +0800</pubDate>
      
      <guid>https://www.sobyte.net/post/2021-10/jupyterlab-hive/</guid>
      <description>The company&amp;rsquo;s data is stored on HDFS, but the model training needs to use this data, so there is a need for data synchronization. The following is a personal data synchronization process, which is only applicable to the company, and may not be available in other places due to different environments.
Data synchronization from Hive to JupyterLab View data file locations via Hive The path to the database table can be viewed via Hive&amp;rsquo;s show create table statement.</description>
    </item>
    
    <item>
      <title>Connecting to Hive using PySpark in Jupyter</title>
      <link>https://www.sobyte.net/post/2021-10/jpuyter-pyspark-hive/</link>
      <pubDate>Sun, 24 Oct 2021 20:44:05 +0800</pubDate>
      
      <guid>https://www.sobyte.net/post/2021-10/jpuyter-pyspark-hive/</guid>
      <description>The company&amp;rsquo;s Jupyter environment supports PySpark. this makes it very easy to use PySpark to connect to Hive queries and use. Since I had no prior exposure to Spark at all, I put together some reference material. Spark Context The core module in PySpark is SparkContext (sc for short), and the most important data carrier is RDD, which is like a NumPy array or a Pandas Series, and can be</description>
    </item>
    
    <item>
      <title>Hadoop and Hive Development Environment Build on Windows10</title>
      <link>https://www.sobyte.net/post/2021-06/hadoop-and-hive-development-environment-build-on-windows10/</link>
      <pubDate>Thu, 17 Jun 2021 10:49:21 +0800</pubDate>
      
      <guid>https://www.sobyte.net/post/2021-06/hadoop-and-hive-development-environment-build-on-windows10/</guid>
      <description>There are numerous problems with the installation and operation of components such as Hadoop and Hive on Windows systems
With the help of several Internet references, I completed the construction of Hadoop and Hive development environment on Windows 10. This article documents the specific steps, problems encountered, and corresponding solutions for the entire build process.
Environmental Preparation    Software Version Description     Windows 10 Operating System   JDK 8 Do not use a version greater than or equal to JDK9 for the time being, because unknown exceptions will occur when starting the virtual machine   MySQL 8.</description>
    </item>
    
  </channel>
</rss>

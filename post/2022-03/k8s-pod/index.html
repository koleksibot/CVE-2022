<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Getting Started with Kubernetes - Pods Explained - SoByte</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6356451834813761" crossorigin="anonymous"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-E8GRRGBTEZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E8GRRGBTEZ');
</script>


<meta name="author" content="" /><meta name="description" content="Pods are the basic scheduling unit of k8s and are the key to k8s. This article explains how to publish and manage applications in k8s, starting from Pod usage, control, scheduling, and application configuration. Pod Basic Usage The requirement for a long-running container is that its main application needs to be running in the foreground at all times. kubelet creates a Pod containing this container, then runs the command, considers" /><meta name="keywords" content="kubernetes, Pods" />






<meta name="generator" content="Hugo 0.92.2 with theme even" />


<link rel="canonical" href="https://www.sobyte.net/post/2022-03/k8s-pod/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Getting Started with Kubernetes - Pods Explained" />
<meta property="og:description" content="Pods are the basic scheduling unit of k8s and are the key to k8s. This article explains how to publish and manage applications in k8s, starting from Pod usage, control, scheduling, and application configuration. Pod Basic Usage The requirement for a long-running container is that its main application needs to be running in the foreground at all times. kubelet creates a Pod containing this container, then runs the command, considers" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.sobyte.net/post/2022-03/k8s-pod/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-03-12T10:46:53+08:00" />
<meta property="article:modified_time" content="2022-03-12T10:46:53+08:00" />

<meta itemprop="name" content="Getting Started with Kubernetes - Pods Explained">
<meta itemprop="description" content="Pods are the basic scheduling unit of k8s and are the key to k8s. This article explains how to publish and manage applications in k8s, starting from Pod usage, control, scheduling, and application configuration. Pod Basic Usage The requirement for a long-running container is that its main application needs to be running in the foreground at all times. kubelet creates a Pod containing this container, then runs the command, considers"><meta itemprop="datePublished" content="2022-03-12T10:46:53+08:00" />
<meta itemprop="dateModified" content="2022-03-12T10:46:53+08:00" />
<meta itemprop="wordCount" content="2710">
<meta itemprop="keywords" content="kubernetes," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Getting Started with Kubernetes - Pods Explained"/>
<meta name="twitter:description" content="Pods are the basic scheduling unit of k8s and are the key to k8s. This article explains how to publish and manage applications in k8s, starting from Pod usage, control, scheduling, and application configuration. Pod Basic Usage The requirement for a long-running container is that its main application needs to be running in the foreground at all times. kubelet creates a Pod containing this container, then runs the command, considers"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">SoByte</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="/ukraine/">
        <li class="mobile-menu-item">UKRAINE</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">SoByte</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/ukraine/">UKRAINE</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Getting Started with Kubernetes - Pods Explained</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-03-12 10:46:53 </span>
        <div class="post-category">
            <a href="/categories/tutorials/"> tutorials </a>
            </div>
          <span class="more-meta"> 2710 words </span>
          <span class="more-meta"> 6 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#pod-basic-usage">Pod Basic Usage</a></li>
        <li><a href="#static-pods">Static Pods</a></li>
        <li><a href="#pod-configuration-management---configmap">Pod Configuration Management - ConfigMap</a>
          <ul>
            <li><a href="#usage">Usage</a></li>
            <li><a href="#configmap-creation">ConfigMap creation</a></li>
            <li><a href="#how-to-use-configmap">How to use ConfigMap</a></li>
            <li><a href="#constraints-of-configmap">Constraints of ConfigMap</a></li>
          </ul>
        </li>
        <li><a href="#pod-lifecycle-and-restart-policy">Pod Lifecycle and Restart Policy</a>
          <ul>
            <li><a href="#pod-states">Pod states</a></li>
            <li><a href="#pod-reboot-policies">Pod reboot policies</a></li>
            <li><a href="#the-restart-policy-of-each-controller-for-pods">The restart policy of each controller for Pods</a></li>
          </ul>
        </li>
        <li><a href="#health-checks">Health checks</a>
          <ul>
            <li><a href="#livenessprobe-survival-check">LivenessProbe (Survival check)</a></li>
            <li><a href="#readinessprobe-readiness-check">ReadinessProbe (readiness check)</a></li>
            <li><a href="#probe-setting-method">Probe setting method</a></li>
          </ul>
        </li>
        <li><a href="#pod-scheduling">Pod Scheduling</a>
          <ul>
            <li><a href="#rs-deployment-fully-automated-scheduling">RS, Deployment Fully Automated Scheduling</a></li>
            <li><a href="#daemonset-scenario-specific-scheduling">DaemonSet Scenario-Specific Scheduling</a></li>
            <li><a href="#job-batch-scheduling">Job Batch Scheduling</a></li>
          </ul>
        </li>
        <li><a href="#pod-scaling-up-and-down">Pod Scaling Up and Down</a>
          <ul>
            <li><a href="#scale-mechanism-for-rc">Scale mechanism for RC</a></li>
            <li><a href="#hpa">HPA</a></li>
          </ul>
        </li>
        <li><a href="#rolling-upgrades">Rolling Upgrades</a>
          <ul>
            <li><a href="#using-yaml-configuration-file">Using yaml configuration file</a></li>
            <li><a href="#not-using-yaml-configuration-file">Not using yaml configuration file</a></li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>Pods are the basic scheduling unit of k8s and are the key to k8s. This article explains how to publish and manage applications in k8s, starting from Pod usage, control, scheduling, and application configuration.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2022/03/12/4004fca52a5e44dfa291d63bde449c0e.png" alt="k8s pod"></p>
<h2 id="pod-basic-usage">Pod Basic Usage</h2>
<p>The requirement for a long-running container is that its main application needs to be running in the foreground at all times. kubelet creates a Pod containing this container, then runs the command, considers the execution of the Pod finished, and immediately destroys the Pod, and according to the number of copies of the Pod defined in RS, a new Pod is immediately created, which will enter an infinite loop.</p>
<p>Multiple container applications belonging to a Pod only need to communicate with each other through localhost, and a group of containers are bound in a single environment.</p>
<p>Containers in the same Pod share the Pod-level Volume, and each container can mount the Volume as a directory that is needed inside the container individually.</p>
<h2 id="static-pods">Static Pods</h2>
<p>Static pods are pods managed by kubelet that exist only on a specific Node; they cannot be managed by APIServer, cannot be associated with RS, etc.</p>
<p><strong>How to create a static pod:</strong></p>
<p>Static pods can be created in two ways, the configuration file way and the HTTP way.</p>
<p><strong>Configuration file method:</strong></p>
<p>Set the kubelet startup parameter &ndash;config to specify the directory where the kubelet needs to monitor the configuration files, and the kubelet will periodically scan the directory and create operations based on the .yaml or .json files in the directory. Since static pods cannot be managed directly by APIServer, trying to delete this pod on the Master node will turn it into a pending state and it will not be deleted; if you need to delete this pod, you need to remove its definition file from the /etc/kubelet.d directory on the Node where it resides.</p>
<p><strong>HTTP method:</strong></p>
<p>Set the kubelet startup parameter &ndash;manifest-url and the kubelet will periodically download the pod definition file from the URL address, parse it as a .yaml or .json file, and create the pod in the same way as the configuration file.</p>
<h2 id="pod-configuration-management---configmap">Pod Configuration Management - ConfigMap</h2>
<p>A best practice for application deployment is to separate the configuration information required by the application from the application, with the benefit of enabling the application to be taken better and more flexible through different configurations. configMap is a unified cluster configuration management solution for k8s.</p>
<h3 id="usage">Usage</h3>
<p>Generate environment variables for containers, set startup parameters for container startup commands, mount them as files or directories inside containers in the form of Volume, and save them as key:value, which can represent both the value of a variable and the content of a complete configuration file.</p>
<p><code>blog.cdn.updev.cn</code></p>
<h3 id="configmap-creation">ConfigMap creation</h3>
<p>By yaml file: After writing the yaml file, the <code>kubectl create -f ***.yaml</code> command creates the ConfigMap.</p>
<p>Directly using the <code>kubectl create configmap</code> command line: ConfigMap can be created based on directories, files, or literal values.</p>
<ol>
<li>
<p>can be created from a directory with the <code>-from-file</code> parameter.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl create configmap &lt;map-name&gt; --from-file<span class="o">=</span>config-files-dir
</code></pre></td></tr></table>
</div>
</div><p>where <code>&lt;map-name&gt;</code> is the name of the ConfigMap and <code>config-files-dir</code> is the directory. The key of the created ConfigMap is the file name.</p>
</li>
<li>
<p>can be created from a file with the <code>-from-file</code> parameter and customize the key.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl create configmap &lt;map-name&gt; --from-file<span class="o">=</span>&lt;my-key-name&gt;<span class="o">=</span>&lt;path-to-file&gt;
</code></pre></td></tr></table>
</div>
</div><p>where <code>my-key-name</code> is a custom key and <code>path-to-file</code> represents a file.</p>
</li>
<li>
<p>can be created from the file with the <code>-from-literal</code> parameter and specify the literal value.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl create configmap &lt;map-name&gt; --from-literal<span class="o">=</span>&lt;key&gt;<span class="o">=</span>&lt;value&gt;
</code></pre></td></tr></table>
</div>
</div><p>where <code>&lt;key&gt;=&lt;value&gt;</code> represents the specified key-value pair.</p>
</li>
</ol>
<h3 id="how-to-use-configmap">How to use ConfigMap</h3>
<p>The following is how to use ConfigMap for applications in containers, mainly the environment variable method and the mount volume method.</p>
<h4 id="environment-variable-method">Environment variable method</h4>
<p>Define env in the container of Deployment&rsquo;s yaml. The format is as follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yml" data-lang="yml"><span class="nt">env</span><span class="p">:</span><span class="w">
</span><span class="w"></span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">HDLS_KEY</span><span class="w">
</span><span class="w">  </span><span class="nt">valueFrom</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">configMapKeyRef</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">special-config</span><span class="w">
</span><span class="w">      </span><span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">hdls</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>means: The value of the environment variable <code>HDLS_KEY</code> in this container is taken from the ConfigMap named <code>special-config</code> with the key <code>hdls</code>.</p>
<h4 id="volumemount-mode">volumeMount mode</h4>
<p>You need to define volumeMounts in the container of the Pod&rsquo;s yaml (referencing the volume name and the directory to be mounted in the container), and define the volume name and ConfigMap etc. in the volumes that need to be mounted. As follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yml" data-lang="yml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hdls-pod</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hdls-container</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">...</span><span class="w">
</span><span class="w">    </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">    </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">   </span><span class="c"># 在 container 中定义 volumeMounts</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hdls-server  </span><span class="w"> </span><span class="c"># 引用的 volume 名</span><span class="w">
</span><span class="w">      </span><span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/configfiles  </span><span class="w"> </span><span class="c"># 挂载到容器中的目录</span><span class="w">
</span><span class="w">  </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hdls-server  </span><span class="w"> </span><span class="c"># pod 中挂载的 Volume 名</span><span class="w">
</span><span class="w">    </span><span class="nt">configMap</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">special-config  </span><span class="w"> </span><span class="c"># 使用 ConfigMap &#34;special-config&#34;</span><span class="w">
</span><span class="w">  </span><span class="l">...</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="constraints-of-configmap">Constraints of ConfigMap</h3>
<ol>
<li>must be created before the Pod.</li>
<li>Only Pods in the same namespace can be referenced.</li>
<li>no quota management.</li>
<li>Static Pods cannot use ConfigMap.</li>
<li>When a Pod mounts a ConfigMap, the container can only be mounted as a directory inside the container, not as a file.</li>
</ol>
<h2 id="pod-lifecycle-and-restart-policy">Pod Lifecycle and Restart Policy</h2>
<p>When scheduling and managing Pods, we need to be familiar with the various states of Pods throughout their lifecycle, and setting up Pod restart policies is also based on knowledge of the various states of Pods.</p>
<h3 id="pod-states">Pod states</h3>
<p>There are a total of 5 states of Pods, which are as follows.</p>
<p><strong>Pending</strong> : APIServer has created the Pod, but there are still images of containers in the Pod that have not been created or are being downloaded.
<strong>Running</strong>: all containers in the Pod have been created, and at least one container is running, starting, or restarting; <strong>Succeeded</strong>: all containers in the Pod have been created, and at least one container is running, starting, or restarting.
<strong>Succeeded</strong> : all containers in the Pod have been successfully exited and will not be restarted; <strong>Succeeded</strong> : all containers in the Pod have been successfully exited and will not be restarted.
<strong>Failed</strong> : all the containers in the Pod have exited, but at least one container is in a failed state; <strong>Failed</strong> : all the containers in the Pod have exited, but at least one container is in a failed state.
<strong>Unknown</strong> : The status of the Pod is not available for some reason, probably due to poor network.</p>
<h3 id="pod-reboot-policies">Pod reboot policies</h3>
<p>There are 3 restart policies for Pods, the default value is Always.</p>
<p><strong>Always</strong> : kubelet automatically restarts the container when it fails.
<strong>OnFailure</strong> : restart when the container is terminated and the exit code is not 0.
<strong>Never</strong> : kubelet does not restart the container, regardless of the status.</p>
<p>The time interval between kubelet restarts of failed containers is calculated by multiplying sync-frequency by 2n, with a maximum delay of 5 minutes, and resetting that time 10 minutes after a successful restart.</p>
<h3 id="the-restart-policy-of-each-controller-for-pods">The restart policy of each controller for Pods</h3>
<p>The reboot policy for Pods is related to the control method, and each controller requires the following reboot policy for Pods.</p>
<p><strong>RS and DaemonSet</strong>: Must be set to Always
<strong>Job</strong>: OnFailure or Never
<strong>kubelet</strong> (Static Pod): Pod restarts automatically when it fails and no health checks are performed</p>
<h2 id="health-checks">Health checks</h2>
<p>There are two types of Pod health checks: Survival check and Readiness check, using the LivenessProbe probe and ReadinessProbe probe respectively.</p>
<h3 id="livenessprobe-survival-check">LivenessProbe (Survival check)</h3>
<p>Once a container is detected to be unhealthy, the kubelet kills the container and handles it accordingly according to the restart policy. If the container does not contain the LivenessProbe probe, the kubelet assumes that the return value is always success.</p>
<h3 id="readinessprobe-readiness-check">ReadinessProbe (readiness check)</h3>
<p>Used to determine whether the container is ready or not. If a failure is detected, the Pod&rsquo;s state is overwritten and the Pod&rsquo;s Endpoint is removed from the Service&rsquo;s forwarding Endpoint.</p>
<h3 id="probe-setting-method">Probe setting method</h3>
<ul>
<li>ExecAction ：Execute a command in the container, if the return code of the command is 0, it indicates that the container is healthy.</li>
<li>TCPSocketAction ：execute TCP check through the container&rsquo;s IP and port number, if a TCP connection can be established, it indicates that the container is healthy.</li>
<li>HTTPGetAction : call the HTTP Get method through the container&rsquo;s IP address, port number and path, if the return code &gt;= 200 and &lt; 400, the container is considered healthy.</li>
</ul>
<p>Each of the above detection methods need to set the parameters.</p>
<ul>
<li>initialDelaySeconds: the time to delay the check, the unit is s</li>
<li>timeoutSeconds: health check sent after the timeout waiting for a response, in s</li>
<li>periodSeconds: execution period</li>
</ul>
<h2 id="pod-scheduling">Pod Scheduling</h2>
<p>Pod is the smallest scheduling unit in k8s, it is just a carrier for containers, and it cannot perform automatic scheduling functions by itself. k8s uses RS, Deployment, DaemonSet, Job, etc. to achieve scheduling and automation of Pods.</p>
<h3 id="rs-deployment-fully-automated-scheduling">RS, Deployment Fully Automated Scheduling</h3>
<p>One of the main functions of RS is to automatically deploy multiple copies of a container application, and continuously monitor the number of copies. RS/RC is rarely used alone in k8s, but in Deployment, which is a concept introduced by k8s to better solve the Pod scheduling problem, and through Deployment we can know the Pod scheduling situation at any time.</p>
<p>In the definition of Pod, the scheduling can be done in two ways, NodeSelector or NodeAffinity.</p>
<h4 id="nodeselector-directed-scheduling">NodeSelector Directed Scheduling</h4>
<p>Pod scheduling is implemented through the Scheduler on the Master, by matching the Node tag with the Pod&rsquo;s nodeSelector property.</p>
<p>The NodeSelector scheduling process is as follows: label the target Node with a kubectl label; add the nodeSelector setting to the Pod definition. Note that once a Pod has specified a nodeSelector, if there is no matching Node in the cluster, it will not be scheduled even if there is a free Node.</p>
<p>The method of tagging via <code>kubectl</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;<span class="o">=</span>&lt;label_value&gt;
</code></pre></td></tr></table>
</div>
</div><p>Specify the nodeSelector in the Pod.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yml" data-lang="yml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hdls</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hdls-pod</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">hdls-container</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">...</span><span class="w">
</span><span class="w">        </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">containerPort</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">      </span><span class="nt">nodeSelector</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">&lt;label-key&gt;</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;label_value&gt;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h4 id="nodeaffinity-affinity-scheduling">NodeAffinity Affinity Scheduling</h4>
<p>NodeAffinity means Node affinity scheduling policy, which is the next generation scheduling policy to replace NodeSelector. It adds In/NotIn/Exists/DoesNotExsist/Gt/Lt operations on top of NodeSelector.</p>
<p>Set affinity.</p>
<ul>
<li>requiredDuringSchedulingRequiredDuringExecution: similar to NodeSelector, when a Node does not satisfy the condition, the system removes the Pod on the previous scheduling from that Node.</li>
<li>requiredDuringSchedulingIgnoredDuringExecution: If the Node does not meet the condition, the system does not necessarily remove the previously scheduled Pod from the Node.</li>
<li>preferredDuringSchedulingIgnoredDuringExecution: Specifies which of the Nodes that satisfy the condition are scheduled more preferentially; also, the Pods on the previous schedule are not necessarily removed from the Node when the Node does not satisfy the condition.</li>
</ul>
<h3 id="daemonset-scenario-specific-scheduling">DaemonSet Scenario-Specific Scheduling</h3>
<p>DaemonSet is a new resource object in Kubernetes 1.2 that ensures that a copy of a Pod is running on all (or some specified) Nodes. Its Pod scheduling policy is similar to RC.</p>
<p>Usage scenarios.</p>
<ol>
<li>run a daemon process for GlusterFS storage or Ceph storage on each Node</li>
<li>Run a logging application such as fluentd, logstach on each Node.</li>
<li>Run a health application on each Node to collect performance data of the Node</li>
</ol>
<h3 id="job-batch-scheduling">Job Batch Scheduling</h3>
<p>Job is a new resource object in Kubernetes 1.2 that supports batch processing. Batch jobs typically start multiple compute processes in parallel or serially to process a batch of work items, and then the entire Job ends when it is finished.</p>
<h4 id="the-modes-of-job">The modes of Job</h4>
<ol>
<li>Job Template Expansion mode: one Job corresponds to one work item. Usually suitable for scenarios where there are few work items and each work item has a large amount of data to process.</li>
<li>Queue with Pod Per Work Item pattern: A task queue is used to store work items and Job objects consume these work items. In this pattern, a Pod corresponds to a work item, and a Job starts multiple Pods.</li>
<li>Queue with Variable Pod Count pattern: the same as the above pattern, the only difference is that the number of Pods started by a Job is variable.</li>
<li>Single Job with Static Work Assignment pattern: This is also a pattern in which a Job generates multiple Pods, but it uses a programmatic static approach to assigning tasks instead of a queue pattern.</li>
</ol>
<h4 id="types-of-jobs">Types of Jobs</h4>
<p>Taking into account the parallelism of batch processing, Jobs are classified into the following types.</p>
<ol>
<li>Non-parallel Jobs: one Job starts one Pod.</li>
<li>Parallel Jobs with a fixed completion count: Parallel Jobs start multiple Pods. The .spec.parallelism parameter is the number of Pods that process a work item simultaneously.</li>
<li>Parallel Jobs with a work queue: Parallel Jobs have a separate queue to store work items, and the .spec.completions parameter cannot be set here.</li>
</ol>
<h2 id="pod-scaling-up-and-down">Pod Scaling Up and Down</h2>
<p>In real production systems, service scaling is a scenario that cannot be ignored. In k8s, there are two ways to scale up and down Pods, namely RC&rsquo;s Scale mechanism and HPA (Horizontal Pod Autoscaler).</p>
<h3 id="scale-mechanism-for-rc">Scale mechanism for RC</h3>
<p>The number of copies of a Pod can be set by the <code>kebectl</code> command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl scale rc &lt;rc-name&gt; --replicas<span class="o">=</span><span class="m">3</span>
</code></pre></td></tr></table>
</div>
</div><p>By manually increasing the number of copies of Pods with the <code>-replicas=&lt;num&gt;</code> parameter, Pod expansion can be accomplished; accordingly, by setting the parameter to a lower number, the system will kill some running Pods to achieve application cluster shrinkage.</p>
<h3 id="hpa">HPA</h3>
<p>HPA (Horizontal Pod Autoscaler) is a new controller added to Kubernetes v1.1 to enable automatic Pod scaling based on CPU usage. pod-autoscaler-sync-period (default is 30 seconds), the HPA periodically checks the CPU usage of the target Pod and adjusts the number of Pod copies in RC or Deployment to match the user-defined average Pod CPU usage when the conditions are met. heapster component, so you need to install heapster beforehand.</p>
<p>The HPA can be created using the <code>kubectlautoscale</code> command or by using the yaml configuration file. Before creating an HPA, make sure that an RC or Deployment object already exists and that the Pod in the RC or Deployment must define the resource request value for resources.requests.cpu.</p>
<h2 id="rolling-upgrades">Rolling Upgrades</h2>
<p>In real production environments, application upgrades are also an important scenario. When the cluster is large, a full stop and then a gradual upgrade can result in unavailability of the service for a longer period of time, and the upgrade becomes a considerable challenge. k8s provides a rolling upgrade feature to solve this problem.</p>
<p>Rolling upgrade is done by executing the <code>kubectl rolling-update</code> command with one click. The whole process is:</p>
<ol>
<li>create a new RC.</li>
<li>automatically reduce the number of Pod copies in the old RC to 0. 3.</li>
<li>at the same time, the number of Pod copies in the new RC gradually increases from 0 to the target value, and each time the old Pod is reduced by 1, the new Pod is increased by 1.</li>
</ol>
<p>Note that the old and new RCs must be in the same namespace.</p>
<h3 id="using-yaml-configuration-file">Using yaml configuration file</h3>
<p>If you use yaml configuration file to achieve rolling upgrade, you need to create a new RC yaml manually first, and the yaml file needs to pay attention to the following: 1.</p>
<ol>
<li>the RC name should not be the same as the old RC name.</li>
<li>there should be at least one Label in the selector that is different from the Label of the old RC to identify it as the new RC.</li>
</ol>
<p>Then run the <code>kubectl</code> command to complete the rolling upgrade.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl rolling-update &lt;RC-name&gt; -f &lt;new-RC-yaml&gt;
</code></pre></td></tr></table>
</div>
</div><h3 id="not-using-yaml-configuration-file">Not using yaml configuration file</h3>
<p>Instead of using the yaml configuration file, you can use the <code>kubectl rolling-update</code> command with the <code>--image</code> parameter to specify the name of the new version of the image.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl rolling-update &lt;RC-name&gt; --image<span class="o">=</span>&lt;image-name&gt;
</code></pre></td></tr></table>
</div>
</div><p>Unlike using the configuration file, this method results in the old RC being deleted, the new RC still using the old RC name, and the new RC having an additional Label with the key &ldquo;deployment&rdquo; (this name can be changed with the <code>--deployment-label-key</code> parameter) after the upgrade is completed, and the value being the Hash calculated from the RC&rsquo;s contents.</p>
<p>Finally, if the Pod needs to be rolled back, you can interrupt the update operation and execute <code>-kubectl rolling-update-rollback</code> to complete the rollback of the Pod version.</p>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kubernetes/">kubernetes</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2022-03/django-signaling-mechanism/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Django&#39;s signaling mechanism</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/2022-03/python-coroutine/">
            <span class="next-text nav-default">Python Coroutine</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://www.sobyte.net/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Zero-Copy Optimization in the Golang - SoByte</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6356451834813761" crossorigin="anonymous"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-E8GRRGBTEZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E8GRRGBTEZ');
</script>


<meta name="author" content="" /><meta name="description" content="This article describes zero-copy optimization in the Go language." /><meta name="keywords" content="golang, Zero Copy" />






<meta name="generator" content="Hugo 0.92.2 with theme even" />


<link rel="canonical" href="https://www.sobyte.net/post/2022-03/golang-zero-copy/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Zero-Copy Optimization in the Golang" />
<meta property="og:description" content="This article describes zero-copy optimization in the Go language." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.sobyte.net/post/2022-03/golang-zero-copy/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-03-22T19:26:27+08:00" />
<meta property="article:modified_time" content="2022-03-22T19:26:27+08:00" />

<meta itemprop="name" content="Zero-Copy Optimization in the Golang">
<meta itemprop="description" content="This article describes zero-copy optimization in the Go language."><meta itemprop="datePublished" content="2022-03-22T19:26:27+08:00" />
<meta itemprop="dateModified" content="2022-03-22T19:26:27+08:00" />
<meta itemprop="wordCount" content="3504">
<meta itemprop="keywords" content="golang," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Zero-Copy Optimization in the Golang"/>
<meta name="twitter:description" content="This article describes zero-copy optimization in the Go language."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">SoByte</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="/ukraine/">
        <li class="mobile-menu-item">UKRAINE</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">SoByte</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/ukraine/">UKRAINE</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Zero-Copy Optimization in the Golang</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-03-22 19:26:27 </span>
        <div class="post-category">
            <a href="/categories/tutorials/"> tutorials </a>
            </div>
          <span class="more-meta"> 3504 words </span>
          <span class="more-meta"> 17 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#splice">splice</a></li>
        <li><a href="#pipe-pool-for-splice">pipe pool for splice</a>
          <ul>
            <li><a href="#pipe-pool-in-haproxy">pipe pool in HAProxy</a></li>
            <li><a href="#pipe-pool-in-go">pipe pool in Go</a></li>
          </ul>
        </li>
        <li><a href="#summary">Summary</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>Anyone familiar with the Go language should be familiar with interfaces and methods such as <code>io.Copy()/io.CopyN()/io.CopyBuffer()/io.ReaderFrom</code>. They are APIs that are often used to transfer data using Go to manipulate various types of I/O. The TCP-based socket makes use of Linux&rsquo;s zero-copy technologies <code>sendfile</code> and <code>splice</code> when transferring data using these interfaces and methods.</p>
<h2 id="splice">splice</h2>
<p>After looking through Linux zero-copy techniques, <code>splice</code> is more suitable as a general-purpose zero-copy method than other techniques such as <code>mmap</code>, <code>sendfile</code> and <code>MSG_ZEROCOPY</code> in terms of cost, performance and applicability.</p>
<p>The <code>splice()</code> system call function is defined as follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="cp">#include</span> <span class="cpf">&lt;fcntl.h&gt;</span><span class="cp">
</span><span class="cp">#include</span> <span class="cpf">&lt;unistd.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="kt">int</span> <span class="nf">pipe</span><span class="p">(</span><span class="kt">int</span> <span class="n">pipefd</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
<span class="kt">int</span> <span class="nf">pipe2</span><span class="p">(</span><span class="kt">int</span> <span class="n">pipefd</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="kt">int</span> <span class="n">flags</span><span class="p">);</span>

<span class="n">ssize_t</span> <span class="nf">splice</span><span class="p">(</span><span class="kt">int</span> <span class="n">fd_in</span><span class="p">,</span> <span class="n">loff_t</span> <span class="o">*</span><span class="n">off_in</span><span class="p">,</span> <span class="kt">int</span> <span class="n">fd_out</span><span class="p">,</span> <span class="n">loff_t</span> <span class="o">*</span><span class="n">off_out</span><span class="p">,</span> <span class="n">size_t</span> <span class="n">len</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">flags</span><span class="p">);</span>
</code></pre></td></tr></table>
</div>
</div><p>fd_in and fd_out also represent the input and output file descriptors, respectively, and one of these two file descriptors must point to a pipeline device, which is a less friendly restriction.</p>
<p>off_in and off_out are pointers to the offsets of fd_in and fd_out respectively, indicating where the kernel reads and writes data from, len indicates the number of bytes the call wishes to transfer, and finally flags is the system call&rsquo;s flag option bitmask, which sets the behavior of the system call, and is a combination of 0 or more of the following values via the &lsquo;or&rsquo; operation .</p>
<ul>
<li>SPLICE_F_MOVE: instructs <code>splice()</code> to try to just move memory pages instead of copying them; setting this value does not necessarily mean that memory pages will not be copied; whether they are copied or moved depends on whether the kernel can move memory pages from the pipeline, or whether the memory pages in the pipeline are intact; the initial implementation of this flag had a lot of bugs, so it has been in place since Linux version 2.6.21, but it has been retained because it may be reimplemented in a future version.</li>
<li>SPLICE_F_NONBLOCK: instructs <code>splice()</code> not to block I/O, i.e. makes the <code>splice()</code> call a non-blocking call that can be used to implement asynchronous data transfers, but note that it is also best to pre-mark the two file descriptors for data transfers as non-blocking I/O with O_NONBLOCK, otherwise Otherwise, the <code>splice()</code> call may still be blocked.</li>
<li>SPLICE_F_MORE: informs the kernel that more data will be transferred with the next <code>splice()</code> system call, this flag is useful for scenarios where the output side is a socket.</li>
</ul>
<p><code>splice()</code> is based on Linux&rsquo;s pipe buffer mechanism, so the two incoming file descriptors of <code>splice()</code> require that one of them be a pipe device, and a typical use of <code>splice()</code> is as follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="kt">int</span> <span class="n">pfd</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>

<span class="n">pipe</span><span class="p">(</span><span class="n">pfd</span><span class="p">);</span>

<span class="n">ssize_t</span> <span class="n">bytes</span> <span class="o">=</span> <span class="n">splice</span><span class="p">(</span><span class="n">file_fd</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">pfd</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">4096</span><span class="p">,</span> <span class="n">SPLICE_F_MOVE</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">bytes</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">);</span>

<span class="n">bytes</span> <span class="o">=</span> <span class="n">splice</span><span class="p">(</span><span class="n">pfd</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">socket_fd</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">bytes</span><span class="p">,</span> <span class="n">SPLICE_F_MOVE</span> <span class="o">|</span> <span class="n">SPLICE_F_MORE</span><span class="p">);</span>
<span class="n">assert</span><span class="p">(</span><span class="n">bytes</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">);</span>
</code></pre></td></tr></table>
</div>
</div><p>Diagram of the data transfer process.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2022/03/22/d09b570a48794563b532143d00975f9d.png" alt="linux i/o splice"></p>
<p>Using <code>splice()</code> to complete a read/write from a disk file to a NIC is as follows.</p>
<ol>
<li>the user process calls <code>pipe()</code>, which plunges from the user state into the kernel state, creates an anonymous one-way pipe, <code>pipe()</code> returns, and the context switches from the kernel state back to the user state.</li>
<li>the user process calls <code>splice()</code> to fall from the user state to the kernel state.</li>
<li>the DMA controller copies the data from the hard disk to the kernel buffer, &ldquo;copies&rdquo; it from the write side of the pipe into the pipe, <code>splice()</code> returns, and the context returns from the kernel state to the user state.</li>
<li>the user process calls <code>splice()</code> again, plunging from the user state into the kernel state.</li>
<li>the kernel `copies' the data from the read side of the pipe to the socket buffer, and the DMA controller copies the data from the socket buffer to the NIC.</li>
<li><code>splice()</code> returns and the context switches from kernel state back to user state.</li>
</ol>
<p>The above is the basic workflow and principle of <code>splice</code>, which is simply to pass the memory page pointer instead of the actual data during data transfer to achieve zero copy.</p>
<h2 id="pipe-pool-for-splice">pipe pool for splice</h2>
<h3 id="pipe-pool-in-haproxy">pipe pool in HAProxy</h3>
<p>As you can see from the introduction of <code>splice</code> above, the implementation of zero-copy data through it requires the use of a medium - <code>pipe</code> (introduced by Linus in 2005), probably because the application of <code>pipe</code> in the Linux IPC mechanism is relatively mature, so the use of pipe to implement <code>splice</code>, although the Linux Although the Linux Kernel team said at the beginning of <code>splice</code> that the pipe limitation could be removed in the future, it has not been implemented for more than a decade, so <code>splice</code> is still tied to <code>pipe</code>.</p>
<p>The problem is that if <code>splice</code> is used only for a single bulk data transfer, the overhead of creating and destroying <code>pipe</code> is almost negligible, but if <code>splice</code> is used frequently for data transfer, for example, in scenarios where a large number of network sockets need to be forwarded, the frequency of creating and destroying <code>pipe</code> also Each call to <code>splice</code> creates a pair of <code>pipe</code> pipe descriptors and destroys them later, which is a huge drain on a network system.</p>
<p>The natural solution to this problem is to think of &ldquo;reuse&rdquo;, such as the famous HAProxy.</p>
<blockquote>
<p>HAProxy is a free and open source software written in C language that provides high availability, load balancing, and TCP and HTTP based application proxying. HAProxy is used by well-known sites such as GitHub, Bitbucket, Stack Overflow, Reddit, Tumblr, Twitter, and Tuenti, as well as Amazon Web Services.</p>
</blockquote>
<p>Because of the need to do traffic forwarding, it can be imagined that HAProxy inevitably has to use <code>splice</code> in high frequency, so the overhead of creating and destroying pipe buffers brought by <code>splice</code> can&rsquo;t be tolerated, so we need to implement a pipe pool to reduce the consumption of system calls by reusing pipe buffers, let&rsquo;s analyze it in detail Let&rsquo;s take a closer look at the design of the HAProxy pipe pool.</p>
<p>First of all, let&rsquo;s think about how a simple pipe pool should be implemented, the most direct and simple implementation is undoubtedly: a single linkedlist + a mutual exclusion lock. Arrays can make better use of CPU cache to speed up access because of the continuity of data allocation in memory, but first of all, for a thread running on a CPU, only one pipe buffer needs to be taken at a time, so the role of cache is not very obvious here; secondly, arrays are not only Second, arrays are not only contiguous but also fixed-size memory areas, which require pre-allocation of a fixed size of memory and dynamic scaling of this memory area, during which the data needs to be relocated and other operations, adding additional management costs. A linked table is a more suitable choice because as a pool all the resources are equivalent and there is no need to access randomly to get a particular resource, and a linked table is naturally dynamically scalable and can be discarded as it is taken.</p>
<p>Early implementations of locks on Linux were based entirely on kernel sleep-waiting, where the kernel maintains a shared resource object mutex that is visible to all processes/threads, and locking and unlocking by multiple threads/processes is actually a competition for this object. If there are two processes/threads AB, A first enters the kernel space to check the mutex to see if another process/thread is occupying it, and then enters the critical zone directly after the mutex is successfully occupied. Then the kernel will wake up the waiting process/thread and switch the CPU to that process/thread at the right time. Since the original mutex was a fully kernel-state implementation of mutual exclusion, which generated a lot of system calls and context switching overhead in case of high concurrency, after Linux kernel 2.6.x, futexes (Fast Userspace Mutexes) are used, which is a mixed implementation of user and kernel states, by sharing a section of memory in the user state and using The semaphore is stored in private memory within the process as a thread lock, and in shared memory created by <code>mmap</code> or <code>shmat</code> as a process lock.</p>
<p>Even for futex-based mutual exclusion locks, if it is a global lock, this simplest pool + mutex implementation has predictable performance bottlenecks in competitive scenarios, so further optimization is needed, by two means: reducing the granularity of the lock or reducing the frequency of robbing (global) locks. Since the resources in the pipe pool are originally shared globally, it is impossible to downgrade the granularity of locks, so the only way to minimize the frequency of multi-threaded lock grabbing is to introduce a local resource pool in addition to the global resource pool to stagger the operations of multi-threaded access to resources.</p>
<p>As for the optimization of the lock itself, since mutex is a kind of dormant waiting lock, even after futex-based optimization in the lock competition still needs to involve the kernel state overhead, you can consider the use of spin lock (Spin Lock), that is, the user state lock, shared resource objects exist in the memory of the user process, to avoid the lock competition into the kernel state waiting, spin lock is more suitable for Spin Lock is more suitable for scenarios where the critical area is very small, while pipe pool&rsquo;s critical area is only for adding and deleting operations to the linkedlist, which is a good match.</p>
<p>The pipe pool implemented by HAProxy is designed based on the above idea, splitting a single global resource pool into a global resource pool + a local resource pool.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2022/03/22/7f9850d0bd334011adab2bd0b64936f2.png" alt="Pipe pool in HAproxy"></p>
<p>Global resource pools are implemented using single-linked tables and spin locks, while local resource pools are implemented based on Thread Local Storage (TLS), a private thread variable whose main purpose is to avoid the overhead of lock contention in multi-threaded programming. <code>TLS</code> is supported by the compiler, and we know that the <code>obj</code> of a compiled C program or the <code>exe</code> of a linked program has a <code>.text</code> segment to store code text, a <code>.data</code> segment to store initialized global variables and initialized static variables, and a <code>.bss</code> segment to store uninitialized global variables and uninitialized local static variables.</p>
<p>Unlike <code>.data</code> and <code>.bss</code>, these segments are not directly accessed by the runtime program, but are dynamically initialized by the dynamic linker after the program starts (if <code>TLS</code> is declared), after which they are not changed again. They are saved as the initial image of <code>TLS</code>. Each time a new thread is started, the <code>TLS</code> block is allocated as part of the thread stack and the initial <code>TLS</code> image is copied over, which means that eventually the contents of the <code>TLS</code> block will be the same for every thread started.</p>
<p>The principle of HAProxy&rsquo;s pipe pool implementation.</p>
<ol>
<li>declare a <code>thread_local</code>-modified single-linked table with nodes that are the two pipe descriptors of the pipe buffer, then each thread that needs to use the pipe buffer initializes a <code>TLS</code>-based single-linked table to store pipe buffers.</li>
<li>set a global pipe pool, protected by a spinlock.</li>
</ol>
<p>Each thread will first try to get the pipe from its own <code>TLS</code>, and if it cannot get it, it will lock the global pipe pool to find it; after using the pipe buffer, it will put it back: first try to put it back to the <code>TLS</code>, and according to a certain policy, it will calculate whether there are too many nodes in the local pipe pool chain of the current <code>TLS</code>, and if so, it will be put into the global pipe pool. If so, it is put into the global pipe pool; otherwise, it is put back into the local pipe pool directly.</p>
<p>Although the pipe pool implementation of HAProxy is only 100 lines of code, the design ideas contained in it contain many classic multi-threaded optimization ideas, which is worth reading carefully.</p>
<h3 id="pipe-pool-in-go">pipe pool in Go</h3>
<p>Inspired by HAProxy&rsquo;s pipe pool, I tried to implement a pipe pool for the underlying <code>splice</code> in Golang&rsquo;s <code>io</code> standard library, but students familiar with Go should know that Go has a GMP concurrent scheduler that provides powerful concurrent scheduling capabilities while blocking OS-level threads, so Go does not provide a mechanism similar to <code>TLS</code>. Instead, there are some open source third-party libraries that provide similar functionality, such as <a href="https://github.com/jtolio/gls">gls</a>, but although the implementation is very sophisticated, it is not an official standard library and will directly manipulate the underlying stack, so it is not really recommended for online use.</p>
<p>At the beginning, because Go lacks the <code>TLS</code> mechanism, the first version of go pipe pool I submitted was a very rudimentary implementation of a single linked table + global mutex lock, because this solution does not release the pipe buffers in the resource pool during the life of the process (in fact, HAProxy&rsquo;s pipe pool also has this problem), which means that those This is obviously not a convincing solution, and it was unexpectedly rejected by <a href="https://www.airs.com/ian/">Ian</a>, a core member of the Go team, so I I immediately came up with two new solutions.</p>
<ol>
<li>based on this existing scheme plus a separate goroutine that scans the pipe pool at regular intervals, closing and releasing pipe buffers.</li>
<li>implement pipe pools based on the <code>sync.Pool</code> standard library and use <code>runtime.SetFinalizer</code> to solve the problem of releasing pipe buffers periodically.</li>
</ol>
<p>The first solution requires the introduction of an additional goroutine, and the goroutine adds uncertainty to the design, while the second solution is more elegant, firstly because it is based on `sync. The second is that it uses Go&rsquo;s runtime to solve the problem of releasing pipe buffers at regular intervals, which is much more elegant, so soon I and other Go reviewers agreed on the second option.</p>
<p><code>sync.Pool</code>  is a temporary object cache pool provided by the Go language, which is generally used to reuse resource objects and reduce GC pressure, and can be used wisely to significantly improve program performance. Many top Go open source libraries make heavy use of <code>sync.Pool</code> to improve performance, for example, the most popular third-party HTTP framework in Go <a href="https://github.com/valyala/fasthttp">fasthttp</a> makes heavy use of <code>sync. Pool</code> in the source code, and reaped a performance improvement of nearly 10x over the Go standard HTTP library (not just by this one optimization, of course, but many others). fasthttp&rsquo;s author Aliaksandr Valialkin, a Go contributor who has contributed a lot of code to Go and optimized <code>sync. Pool</code> in fasthttp&rsquo;s <a href="https://github.com/valyala/fasthttp#fasthttp-best-practices">best practices</a>, so Go&rsquo;s pipe pool using <code>sync.Pool</code>  for Go&rsquo;s pipe pool is a natural fit.</p>
<p><code>sync.Pool</code> is simply: private variables + shared bidirectional chains.</p>
<p>Google has a diagram to show the underlying implementation of <code>sync.Pool</code>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2022/03/22/2e0feaf3a2ea4923b88ec6dd51519024.png" alt="sync.Pool"></p>
<ul>
<li>
<p>When fetching an object. When a goroutine on some P tries to fetch a cached object from <code>sync.Pool</code>, it needs to lock the current goroutine on P first to prevent it from being dispatched suddenly during the operation, then try to fetch the local private variable <code>private</code> first, and if it is not there, go to the head of the <code>shared</code> two-way table, which can be consumed by other P (or &ldquo;steal&rdquo;). steal&quot;), if the <code>shared</code> on the current P is empty then go &ldquo;steal&rdquo; the end of the <code>shared</code> two-way linked table on the other P, finally unlock it, and if the cached object is still not fetched, then directly call <code>New</code> to create a return.</p>
</li>
<li>
<p>When putting back the object: first lock the current goroutine on P, if the local <code>private</code> is empty, the object is directly deposited, otherwise it is deposited in the head of the <code>shared</code> two-way linked table, and finally unlocked.</p>
</li>
</ul>
<p>Each node of a shared two-way linked table is a ring queue. Mutex before Go 1.13, and atomic CAS after Go 1.13 for lock-free concurrency. Atomic concurrency is suitable for scenarios where the critical area is very small, and the performance is much better with mutexes, which fits the sync. Pool. Because accessing temporary objects is very fast, if we use mutex, we need to hang the goroutines that failed to grab the lock to the wait queue when competing, and then wake up and put them into the run queue after the subsequent unlocking, waiting for the scheduling execution, rather than just busy polling and waiting, we can grab the critical area soon anyway.</p>
<p><code>sync.Pool</code>  is also designed with some <code>TLS</code> in mind, so in a sense it is a <code>TLS</code> mechanism for the Go language.</p>
<p><code>sync.Pool</code>  <strong>is based on the victim cache which guarantees that resource objects cached in it will be recycled in no more than two GC cycles</strong>.</p>
<p>So I used <code>sync.Pool</code> to implement Go&rsquo;s pipe pool, storing the pipe&rsquo;s file descriptor pairs in it, reusing them when concurrent, and automatically recycling them periodically, but there is one problem: when the objects in `sync. It does not shut down the pipe at the OS level.</p>
<p>Therefore, there is a method to close the pipe, which can be done with <code>runtime.SetFinalizer</code>. When Go&rsquo;s tri-color tagging GC algorithm detects that an object in <code>sync.Pool</code> has become white (unreachable, i.e. garbage) and is ready to be recycled, if the white object has an associated callback function bound to it, the GC will first unbind the callback function and start If the white object is bound to a callback function, the GC will first unbind the callback function and start a separate goroutine to execute the callback function, because the callback function uses the object as a function reference, that is, it will refer to the object, then it will cause the object to become a reachable object again, so it will not be recycled in the current round of GC, so that the life of the object can continue for one GC cycle.</p>
<p>SetFinalizer` to specify a callback function before each pipe buffer is put back into the pipe pool, and use the system call in the function to close the pipe, then you can use Go&rsquo;s GC mechanism to actually recycle the pipe buffers periodically, thus achieving an elegant pipe pool in Go, the relevant commits are as follows.</p>
<ul>
<li><a href="https://github.com/golang/go/commit/643d240a11b2d00e1718b02719707af0708e7519">internal/poll: implement a pipe pool for splice() call</a></li>
<li><a href="https://github.com/golang/go/commit/6382ec1aba1b1c7380cb525217c1bd645c4fd41b">internal/poll: fix the intermittent build failures with pipe pool</a></li>
<li><a href="https://github.com/golang/go/commit/8b859be9c3fd1068b659afa1db76dadb210c63de">internal/poll: ensure that newPoolPipe doesn&rsquo;t return a nil pointer</a></li>
<li><a href="https://github.com/golang/go/commit/832c70e33d8265116f0abce436215b8e9ee4bb08">internal/poll: cast off the last reference of SplicePipe in test</a></li>
</ul>
<p>The introduction of pipe pools for Go&rsquo;s <code>splice</code> has had the following performance improvements.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-txt" data-lang="txt">goos: linux
goarch: amd64
pkg: internal/poll
cpu: AMD EPYC 7K62 48-Core Processor

name                  old time/op    new time/op    delta
SplicePipe-8            1.36µs ± 1%    0.02µs ± 0%   -98.57%  (p=0.001 n=7+7)
SplicePipeParallel-8     747ns ± 4%       4ns ± 0%   -99.41%  (p=0.001 n=7+7)

name                  old alloc/op   new alloc/op   delta
SplicePipe-8             24.0B ± 0%      0.0B       -100.00%  (p=0.001 n=7+7)
SplicePipeParallel-8     24.0B ± 0%      0.0B       -100.00%  (p=0.001 n=7+7)

name                  old allocs/op  new allocs/op  delta
SplicePipe-8              1.00 ± 0%      0.00       -100.00%  (p=0.001 n=7+7)
SplicePipeParallel-8      1.00 ± 0%      0.00       -100.00%  (p=0.001 n=7+7)
</code></pre></td></tr></table>
</div>
</div><p>Compared to creating &amp; destroying pipe buffers directly, pipe pool-based multiplexing reduces time consumption by more than 99% and memory usage by 100%.</p>
<p>Of course, this benchmark is a pure access operation without any specific business logic, so it is a very idealized test and not fully representative of the production environment, but the introduction of pipe pools will definitely improve the performance of high-frequency zero-copy operations based on <code>splice</code> using Go&rsquo;s <code>io</code> standard library by orders of magnitude.</p>
<h2 id="summary">Summary</h2>
<p>By implementing a pipe pool for Go, there are various concurrency and synchronization optimization ideas involved, so let&rsquo;s summarize them.</p>
<ul>
<li>Resource reuse, the most effective means of improving concurrent programming performance must be resource reuse, which is also the most immediate optimization.</li>
<li>Data structure selection, arrays support O(1) random access and better use of CPU cache, but these advantages are not obvious in the pool scenario, because the resources in the pool have equivalence and single access (non-batch) operations, arrays require pre-allocation of fixed memory and additional memory management burden when scaling, chains are discarded as they are taken, and naturally support dynamic Scaling.</li>
<li>There are two ways of thinking about the optimization of global locks. One is to try to downgrade the granularity of locks based on the characteristics of the resource, and the other is to try to stagger access to the resource by introducing local caches to reduce the frequency of competing global locks, and to choose user state locks appropriately based on the actual scenario.</li>
<li>Take advantage of the language runtime. Languages like Go and Java, which come with a huge GC, are generally no match for GC-free languages like C/C++/Rust in terms of performance, but there are pros and cons to everything, and languages that come with runtime also have unique advantages. For example, HAProxy&rsquo;s pipe pool is a C implementation, and the pipe buffers created during the life of the process will always be there to consume resources (unless they are actively closed, but it is difficult to control the timing accurately), while Go&rsquo;s pipe pool can use its own runtime to clean up periodically and further reduce resource consumption.</li>
</ul>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/golang/">golang</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2022-03/golang-grcp-client/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Implementing a simple gRPC client using Golang</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/2022-03/k8s-managed-lifecycle/">
            <span class="next-text nav-default">Lifecycle Management Design Patterns in K8s</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://www.sobyte.net/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Build Streaming Applications Based on Flink Sql - SoByte</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6356451834813761" crossorigin="anonymous"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-E8GRRGBTEZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E8GRRGBTEZ');
</script>


<meta name="author" content="" /><meta name="description" content="Since the release of Flink 1.10.0, many exciting new features have been released. In particular, the Flink SQL module is evolving very fast, so this article is dedicated to exploring how to build a fast streaming application using Flink SQL from a practical point of view. This article will use Flink SQL to build a real-time analytics application for e-commerce user behavior based on Kafka, MySQL, Elasticsearch, Kibana. All the" /><meta name="keywords" content="flink,sql,stream" />






<meta name="generator" content="Hugo 0.92.2 with theme even" />


<link rel="canonical" href="https://www.sobyte.net/post/2021-06/build-streaming-applications-based-on-flink-sql/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Build Streaming Applications Based on Flink Sql" />
<meta property="og:description" content="Since the release of Flink 1.10.0, many exciting new features have been released. In particular, the Flink SQL module is evolving very fast, so this article is dedicated to exploring how to build a fast streaming application using Flink SQL from a practical point of view. This article will use Flink SQL to build a real-time analytics application for e-commerce user behavior based on Kafka, MySQL, Elasticsearch, Kibana. All the" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.sobyte.net/post/2021-06/build-streaming-applications-based-on-flink-sql/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-06-29T17:15:16+08:00" />
<meta property="article:modified_time" content="2021-06-29T17:15:16+08:00" />

<meta itemprop="name" content="Build Streaming Applications Based on Flink Sql">
<meta itemprop="description" content="Since the release of Flink 1.10.0, many exciting new features have been released. In particular, the Flink SQL module is evolving very fast, so this article is dedicated to exploring how to build a fast streaming application using Flink SQL from a practical point of view. This article will use Flink SQL to build a real-time analytics application for e-commerce user behavior based on Kafka, MySQL, Elasticsearch, Kibana. All the"><meta itemprop="datePublished" content="2021-06-29T17:15:16+08:00" />
<meta itemprop="dateModified" content="2021-06-29T17:15:16+08:00" />
<meta itemprop="wordCount" content="2679">
<meta itemprop="keywords" content="flink," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Build Streaming Applications Based on Flink Sql"/>
<meta name="twitter:description" content="Since the release of Flink 1.10.0, many exciting new features have been released. In particular, the Flink SQL module is evolving very fast, so this article is dedicated to exploring how to build a fast streaming application using Flink SQL from a practical point of view. This article will use Flink SQL to build a real-time analytics application for e-commerce user behavior based on Kafka, MySQL, Elasticsearch, Kibana. All the"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">SoByte</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="/ukraine/">
        <li class="mobile-menu-item">UKRAINE</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">SoByte</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/ukraine/">UKRAINE</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Build Streaming Applications Based on Flink Sql</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-06-29 17:15:16 </span>
        <div class="post-category">
            <a href="/categories/skills/"> skills </a>
            <a href="/categories/big-data/"> big-data </a>
            </div>
          <span class="more-meta"> 2679 words </span>
          <span class="more-meta"> 6 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#preparation">Preparation</a>
          <ul>
            <li><a href="#starting-a-container-with-docker-compose">Starting a container with Docker Compose</a></li>
            <li><a href="#download-and-install-flink-local-cluster">Download and install Flink Local Cluster</a></li>
          </ul>
        </li>
        <li><a href="#creating-kafka-tables-with-ddl">Creating Kafka Tables with DDL</a></li>
        <li><a href="#statistics-of-hourly-volume">Statistics of hourly volume</a>
          <ul>
            <li><a href="#creating-elasticsearch-tables-with-ddl">Creating Elasticsearch Tables with DDL</a></li>
            <li><a href="#submit-query">Submit Query</a></li>
            <li><a href="#visualize-results-with-kibana">Visualize results with Kibana</a></li>
          </ul>
        </li>
        <li><a href="#count-the-cumulative-number-of-unique-users-per-10-minutes-a-day">Count the cumulative number of unique users per 10 minutes a day</a></li>
        <li><a href="#top-category-list">Top category list</a></li>
        <li><a href="#ending">Ending</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>Since the release of Flink 1.10.0, many exciting new features have been released. In particular, the Flink SQL module is evolving very fast, so this article is dedicated to exploring how to build a fast streaming application using Flink SQL from a practical point of view.</p>
<p>This article will use Flink SQL to build a real-time analytics application for e-commerce user behavior based on Kafka, MySQL, Elasticsearch, Kibana.</p>
<p>All the walkthroughs in this article will be executed on Flink SQL CLI, involving only SQL plain text, without a single line of Java/Scala code and no IDE installation.</p>
<p>The final result of this walkthrough.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/df08f72c0ffc4aae97ba21ddc4ed83e9.png" alt=" "></p>
<h2 id="preparation">Preparation</h2>
<p>A <code>Linux</code> or <code>MacOS</code> computer with <code>Docker</code> and <code>Java8</code>.</p>
<h3 id="starting-a-container-with-docker-compose">Starting a container with Docker Compose</h3>
<p>The components that this live demo relies on are all scheduled into containers, so they can be started with a single click via <code>docker-compose</code>. You can download the docker-compose.yml file automatically with the <code>wget</code> command, or you can download it manually.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">mkdir flink-demo<span class="p">;</span> <span class="nb">cd</span> flink-demo<span class="p">;</span>
wget https://raw.githubusercontent.com/wuchong/flink-sql-demo/master/docker-compose.yml
</code></pre></td></tr></table>
</div>
</div><p>The containers included in this <code>Docker Compose</code> are.</p>
<ul>
<li><code>DataGen</code>: Data generator. When the container starts, it automatically starts generating user behavior data and sends it to the <code>Kafka</code> cluster. The default is to generate <code>1000</code> data per second for about 3 hours. You can also change the <code>speedup</code> parameter of <code>datagen</code> in <code>docker-compose.yml</code> to adjust the generation rate (restart <code>docker compose</code> to take effect).</li>
<li><code>MySQL</code>: integrated with MySQL 5.7, and a pre-created category table, pre-filled with mapping relationships between sub-categories and top-level categories, for subsequent use as a dimension table.</li>
<li><code>Kafka</code>: Used primarily as a data source, the DataGen component automatically pours data into this container.</li>
<li><code>Zookeeper</code>: Kafka container dependency.</li>
<li><code>Elasticsearch</code>: Mainly stores the data produced by Flink SQL.</li>
<li><code>Kibana</code>: visualizes the data in Elasticsearch.</li>
</ul>
<p>Before starting the containers, it is recommended to modify the <code>Docker</code> configuration to adjust the resources to <code>4GB</code> and 4 cores. To start all containers, just run the following command in the directory where <code>docker-compose.yml</code> is located.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">docker-compose up -d
</code></pre></td></tr></table>
</div>
</div><p>This command will automatically start all containers defined in the <code>Docker Compose</code> configuration in <code>detached</code> mode. You can use <code>docker ps</code> to see if the above five containers are started properly. You can also visit <code>http://localhost:5601/</code> to see if <code>Kibana</code> is running properly.</p>
<p>Alternatively, all containers can be stopped with the following command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">docker-compose down
</code></pre></td></tr></table>
</div>
</div><h3 id="download-and-install-flink-local-cluster">Download and install Flink Local Cluster</h3>
<p>We recommend that users download and install <code>Flink</code> manually instead of starting <code>Flink</code> automatically via <code>Docker</code>. This is because it is more intuitive to understand the components, dependencies, and scripts of <code>Flink</code>.</p>
<ol>
<li>
<p>Download the Flink 1.10.0 installation package and unzip it (unzip directory flink-1.10.0): <a href="https://www.apache.org/dist/flink/flink-1.10.0/flink-1.10.0-bin-scala_2.11.tgz">https://www.apache.org/dist/flink/flink-1.10.0/flink-1.10.0-bin-scala_2.11.tgz</a></p>
</li>
<li>
<p>Go to the <code>flink-1.10.0</code> directory: cd flink-1.10.0</p>
</li>
<li>
<p>Download the dependent <code>jar</code> packages and copy them to the <code>lib/</code> directory with the following command, or you can download and copy them manually. Because we need to depend on each <code>connector</code> implementation when we run it.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">wget -P ./lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-json/1.10.0/flink-json-1.10.0.jar <span class="p">|</span> <span class="se">\
</span><span class="se"></span>    wget -P ./lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-kafka_2.11/1.10.0/flink-sql-connector-kafka_2.11-1.10.0.jar <span class="p">|</span> <span class="se">\
</span><span class="se"></span>    wget -P ./lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-sql-connector-elasticsearch6_2.11/1.10.0/flink-sql-connector-elasticsearch6_2.11-1.10.0.jar <span class="p">|</span> <span class="se">\
</span><span class="se"></span>    wget -P ./lib/ https://repo1.maven.org/maven2/org/apache/flink/flink-jdbc_2.11/1.10.0/flink-jdbc_2.11-1.10.0.jar <span class="p">|</span> <span class="se">\
</span><span class="se"></span>    wget -P ./lib/ https://repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.48/mysql-connector-java-5.1.48.jar
</code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Change <code>taskmanager.numberOfTaskSlots</code> in <code>conf/flink-conf.yaml</code> to <code>10</code>, since we will be running multiple tasks at the same time.</p>
</li>
<li>
<p>Execute <code>. /bin/start-cluster.sh</code> to start the cluster.
If it runs successfully, you can access <code>Flink Web UI</code> at <code>http://localhost:8081</code>. And you can see the number of available <code>Slots</code> is <code>10</code>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/b84adab32b384da1b5197a13c420bcf2.png" alt=" "></p>
</li>
<li>
<p>Execute <code>bin/sql-client.sh embedded</code> to start <code>SQL CLI</code>. You will see the following squirrel welcome screen.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/0516529368d34ef3aef14e2908fcfa01.png" alt=" "></p>
</li>
</ol>
<h2 id="creating-kafka-tables-with-ddl">Creating Kafka Tables with DDL</h2>
<p>The <code>Datagen</code> container continuously writes data to the <code>user_behavior topic</code> of <code>Kafka</code> after it is started. The data contains user behaviors (behaviors include click, buy, add, like) for one day on November 27, 2017, with each row representing one user behavior in <code>JSON</code> format consisting of user ID, product ID, product category ID, behavior type and time. The original dataset comes from the <a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=649">AliCloud Tianchi public dataset</a>, and we would like to acknowledge it.</p>
<p>We can run the following command in the directory where <code>docker-compose.yml</code> is located to see the first <code>10</code> data generated in the <code>Kafka</code> cluster.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">docker-compose <span class="nb">exec</span> kafka bash -c <span class="s1">&#39;kafka-console-consumer.sh --topic user_behavior --bootstrap-server kafka:9094 --from-beginning --max-messages 10&#39;</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text">{&#34;user_id&#34;: &#34;952483&#34;, &#34;item_id&#34;:&#34;310884&#34;, &#34;category_id&#34;: &#34;4580532&#34;, &#34;behavior&#34;: &#34;pv&#34;, &#34;ts&#34;: &#34;2017-11-27T00:00:00Z&#34;}
{&#34;user_id&#34;: &#34;794777&#34;, &#34;item_id&#34;:&#34;5119439&#34;, &#34;category_id&#34;: &#34;982926&#34;, &#34;behavior&#34;: &#34;pv&#34;, &#34;ts&#34;: &#34;2017-11-27T00:00:00Z&#34;}
...
</code></pre></td></tr></table>
</div>
</div><p>Once we have the data source, we can use the <code>DDL</code> to create and connect to this <code>topic</code> in <code>Kafka</code>. Execute the <code>DDL</code> in the <code>Flink SQL CLI</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">user_behavior</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="n">user_id</span><span class="w"> </span><span class="nb">BIGINT</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="n">item_id</span><span class="w"> </span><span class="nb">BIGINT</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="n">category_id</span><span class="w"> </span><span class="nb">BIGINT</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="n">behavior</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="n">ts</span><span class="w"> </span><span class="k">TIMESTAMP</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span><span class="w">
</span><span class="w">    </span><span class="n">proctime</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">PROCTIME</span><span class="p">(),</span><span class="w">   </span><span class="c1">-- 通过计算列产生一个处理时间列
</span><span class="c1"></span><span class="w">    </span><span class="n">WATERMARK</span><span class="w"> </span><span class="k">FOR</span><span class="w"> </span><span class="n">ts</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">ts</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">INTERVAL</span><span class="w"> </span><span class="s1">&#39;5&#39;</span><span class="w"> </span><span class="k">SECOND</span><span class="w">  </span><span class="c1">-- 在ts上定义watermark，ts成为事件时间列
</span><span class="c1"></span><span class="p">)</span><span class="w"> </span><span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;kafka&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- 使用 kafka connector
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.version&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;universal&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- kafka 版本，universal 支持 0.11 以上的版本
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.topic&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;user_behavior&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- kafka topic
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.startup-mode&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;earliest-offset&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- 从起始 offset 开始读取
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.properties.zookeeper.connect&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;localhost:2181&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- zookeeper 地址
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.properties.bootstrap.servers&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;localhost:9092&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- kafka broker 地址
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;format.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;json&#39;</span><span class="w">  </span><span class="c1">-- 数据源格式为 json
</span><span class="c1"></span><span class="p">);</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>In addition to the <code>5</code> fields declared above in the format of the data, we also declare a virtual column that generates the processing time via the computed column syntax and the <code>PROCTIME()</code> built-in function. We also declare a <code>watermark</code> policy (tolerating 5 seconds of chaos) on the <code>ts</code> field via the <code>WATERMARK</code> syntax, and the <code>ts</code> field thus becomes an event time column. You can read the official documentation for more information about the time attribute and the <code>DDL</code> syntax</p>
<ol>
<li>Time Attributes: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/streaming/time_attributes.html">https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/streaming/time_attributes.html</a></li>
<li>DDL:<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/create.html#create-table">https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/create.html#create-table</a></li>
</ol>
<p>After successfully creating a <code>Kafka</code> table in the <code>SQL CLI</code>, you can view the currently registered tables and the table details by using <code>show tables;</code> and <code>describe user_behavior;</code>. We can also run <code>SELECT * FROM user_behavior;</code> directly in the <code>SQL CLI</code> to preview the data (press q to exit).</p>
<p>Next, we will go deeper into <code>Flink SQL</code> with three real-world scenarios.</p>
<h2 id="statistics-of-hourly-volume">Statistics of hourly volume</h2>
<h3 id="creating-elasticsearch-tables-with-ddl">Creating Elasticsearch Tables with DDL</h3>
<p>We first create an <code>ES</code> result table in the <code>SQL CLI</code>, which needs to save two main data according to the scenario requirements: hours, volume.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">buy_cnt_per_hour</span><span class="w"> </span><span class="p">(</span><span class="w"> 
</span><span class="w">    </span><span class="n">hour_of_day</span><span class="w"> </span><span class="nb">BIGINT</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="n">buy_cnt</span><span class="w"> </span><span class="nb">BIGINT</span><span class="w">
</span><span class="w"></span><span class="p">)</span><span class="w"> </span><span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;elasticsearch&#39;</span><span class="p">,</span><span class="w"> </span><span class="c1">-- 使用 elasticsearch connector
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.version&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;6&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- elasticsearch 版本，6 能支持 es 6+ 以及 7+ 的版本
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.hosts&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;http://localhost:9200&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- elasticsearch 地址
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.index&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;buy_cnt_per_hour&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- elasticsearch 索引名，相当于数据库的表名
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.document-type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;user_behavior&#39;</span><span class="p">,</span><span class="w"> </span><span class="c1">-- elasticsearch 的 type，相当于数据库的库名
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;connector.bulk-flush.max-actions&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;1&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- 每条数据都刷新
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;format.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;json&#39;</span><span class="p">,</span><span class="w">  </span><span class="c1">-- 输出数据格式 json
</span><span class="c1"></span><span class="w">    </span><span class="s1">&#39;update-mode&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;append&#39;</span><span class="w">
</span><span class="w"></span><span class="p">);</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>We don&rsquo;t need to create the <code>buy_cnt_per_hour</code> index in <code>Elasticsearch</code> beforehand, <code>Flink Job</code> will create it automatically.</p>
<h3 id="submit-query">Submit Query</h3>
<p>The hourly volume is the total number of &ldquo;buys&rdquo; made by users per hour. Therefore, we need to use the <code>TUMBLE</code> window function, which cuts the window by hour. Then each window will count the number of &ldquo;buys&rdquo; separately, which can be achieved by filtering out the &ldquo;buys&rdquo; first and then <code>COUNT(*)</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">buy_cnt_per_hour</span><span class="w">
</span><span class="w"></span><span class="k">SELECT</span><span class="w"> </span><span class="n">HOUR</span><span class="p">(</span><span class="n">TUMBLE_START</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span><span class="w"> </span><span class="nb">INTERVAL</span><span class="w"> </span><span class="s1">&#39;1&#39;</span><span class="w"> </span><span class="n">HOUR</span><span class="p">)),</span><span class="w"> </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w">
</span><span class="w"></span><span class="k">FROM</span><span class="w"> </span><span class="n">user_behavior</span><span class="w">
</span><span class="w"></span><span class="k">WHERE</span><span class="w"> </span><span class="n">behavior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;buy&#39;</span><span class="w">
</span><span class="w"></span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">TUMBLE</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span><span class="w"> </span><span class="nb">INTERVAL</span><span class="w"> </span><span class="s1">&#39;1&#39;</span><span class="w"> </span><span class="n">HOUR</span><span class="p">);</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>Here we use the <code>HOUR</code> built-in function to extract the value of the first hour of the day from a <code>TIMESTAMP</code> column. <code>INSERT INTO</code> is used to continuously insert the results of <code>query</code> into the <code>es</code> results table defined above (think of the <code>es</code> results table as a materialized view of <code>query</code>). Also read this document to learn more about window aggregation: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/queries.html#group-windows">https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/queries.html#group-windows</a></p>
<p>After running the above query in <code>Flink SQL CLI</code>, you can see the submitted task in <code>Flink Web UI</code>, which is a streaming task and thus will keep running.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/8d022f62669940a3abc3e0cd85ea51cf.png" alt=" "></p>
<p>You can see that the early morning hours are the low point of the day in terms of volume.</p>
<h3 id="visualize-results-with-kibana">Visualize results with Kibana</h3>
<p>We have started the <code>Kibana</code> container via <code>Docker Compose</code> and can access <code>Kibana</code> via <code>http://localhost:5601</code>. First we need to configure an <code>index pattern</code> first. Click <code>Management</code> in the left toolbar and you will find <code>Index Patterns</code>. Click <code>Create Index Pattern</code> and then create <code>index pattern</code> by entering the full index name <code>buy_cnt_per_hour</code>. Once created, <code>Kibana</code> will know our indexes and we can start exploring the data.</p>
<p>First click the &ldquo;Discovery&rdquo; button on the left toolbar, and <code>Kibana</code> will list the contents of the index you just created.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/b00529e2db14463fb7aa117b7613bfc3.png" alt=" "></p>
<p>Next, let&rsquo;s create a <code>Dashboard</code> to display each visualization view. Click &ldquo;Dashboard&rdquo; on the left side of the page to create a <code>Dashboard</code> called &ldquo;User Behavior Log Analysis&rdquo;. Then click &ldquo;Create New&rdquo; to create a new view, select &ldquo;Area&rdquo; area map, choose &ldquo;buy_cnt_per_hour &quot; index and draw the volume area map as configured in the screenshot below (left side) and save it as &ldquo;Volume per hour&rdquo;.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/f5bb5efa88034daca087726dc88c6926.png" alt=" "></p>
<h2 id="count-the-cumulative-number-of-unique-users-per-10-minutes-a-day">Count the cumulative number of unique users per 10 minutes a day</h2>
<p>Another interesting visualization is to count the cumulative number of unique users (uv) at each moment of the day, i.e., the uv count at each moment represents the total uv count from point 0 to the current moment, so the curve must be monotonically increasing.</p>
<p>We still start by creating an <code>Elasticsearch</code> table in the <code>SQL CLI</code> to store the result summary data. There are two main fields: time and cumulative <code>uv</code> count.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">cumulative_uv</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="n">time_str</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="n">uv</span><span class="w"> </span><span class="nb">BIGINT</span><span class="w">
</span><span class="w"></span><span class="p">)</span><span class="w"> </span><span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;elasticsearch&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.version&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;6&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.hosts&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;http://localhost:9200&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.index&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;cumulative_uv&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.document-type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;user_behavior&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;format.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;json&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;update-mode&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;upsert&#39;</span><span class="w">
</span><span class="w"></span><span class="p">);</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>To achieve this curve, we can first calculate the current minute of each data by <code>OVER WINDOW</code>, and the current cumulative <code>uv</code> (the number of unique users from point 0 to the current row). The <code>uv</code> count is done with the built-in <code>COUNT(DISTINCT user_id</code>), and <code>Flink SQL</code> has a lot of internal optimizations for <code>COUNT DISTINCT</code>, so you can use it without worry.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">uv_per_10min</span><span class="w"> </span><span class="k">AS</span><span class="w">
</span><span class="w"></span><span class="k">SELECT</span><span class="w"> 
</span><span class="w">  </span><span class="k">MAX</span><span class="p">(</span><span class="n">SUBSTR</span><span class="p">(</span><span class="n">DATE_FORMAT</span><span class="p">(</span><span class="n">ts</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;HH:mm&#39;</span><span class="p">),</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="s1">&#39;0&#39;</span><span class="p">)</span><span class="w"> </span><span class="n">OVER</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">time_str</span><span class="p">,</span><span class="w"> 
</span><span class="w">  </span><span class="k">COUNT</span><span class="p">(</span><span class="k">DISTINCT</span><span class="w"> </span><span class="n">user_id</span><span class="p">)</span><span class="w"> </span><span class="n">OVER</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">uv</span><span class="w">
</span><span class="w"></span><span class="k">FROM</span><span class="w"> </span><span class="n">user_behavior</span><span class="w">
</span><span class="w"></span><span class="n">WINDOW</span><span class="w"> </span><span class="n">w</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="p">(</span><span class="k">ORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">proctime</span><span class="w"> </span><span class="k">ROWS</span><span class="w"> </span><span class="k">BETWEEN</span><span class="w"> </span><span class="n">UNBOUNDED</span><span class="w"> </span><span class="n">PRECEDING</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="k">CURRENT</span><span class="w"> </span><span class="k">ROW</span><span class="p">);</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>Here we use <code>SUBSTR</code> and <code>DATE_FORMAT</code> and <code>||</code> built-in functions to convert a <code>TIMESTAMP</code> field into a time string in <code>10</code> minutes, e.g.: <code>12:10</code>, <code>12:20</code>. More about <code>OVER WINDOW</code> can be found in the documentation: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/queries.html#aggregations">https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/sql/queries.html#aggregations</a></p>
<p>We also use the <code>CREATE VIEW</code> syntax to register a <code>query</code> as a logical view that can be easily referenced in subsequent queries, which facilitates the disassembly of complex <code>queries</code>. Note that creating a logical view does not trigger job execution and the results of the view do not land, so it is very lightweight to use and has no additional overhead. Since <code>uv_per_10min</code> produces one output for each input data, it is more stressful for storage. We can do another aggregation based on <code>uv_per_10min</code> based on the time in minutes, so that only one point per <code>10</code> minutes will be stored in <code>Elasticsearch</code>, which will be much less stressful for <code>Elasticsearch</code> and <code>Kibana</code> visual rendering.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">cumulative_uv</span><span class="w">
</span><span class="w"></span><span class="k">SELECT</span><span class="w"> </span><span class="n">time_str</span><span class="p">,</span><span class="w"> </span><span class="k">MAX</span><span class="p">(</span><span class="n">uv</span><span class="p">)</span><span class="w">
</span><span class="w"></span><span class="k">FROM</span><span class="w"> </span><span class="n">uv_per_10min</span><span class="w">
</span><span class="w"></span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">time_str</span><span class="p">;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>After submitting the above query, create an <code>index pattern</code> for <code>cumulative_uv</code> in <code>Kibana</code>, then create a <code>Line</code> line chart in <code>Dashboard</code>, select <code>cumulative_uv</code> index, draw the cumulative number of unique users curve according to the configuration in the screenshot below (left side) and save it.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/7af4c20389ca49a7977cc62d0fb48b11.png" alt=" "></p>
<h2 id="top-category-list">Top category list</h2>
<p>The last interesting visualization is the category ranking, so as to understand which categories are the pillar categories. However, since the category classification in the source data is too fine (about 5000 categories) to be meaningful for the leaderboard, we would like to approximate it to the top categories. So I pre-prepared the mapping data between sub-categories and top categories in the <code>mysql</code> container to be used as a dimension table.</p>
<p>The <code>MySQL</code> table is created in the <code>SQL CLI</code> and later used as a dimension table query.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">category_dim</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="n">sub_category_id</span><span class="w"> </span><span class="nb">BIGINT</span><span class="p">,</span><span class="w">  </span><span class="c1">-- 子类目
</span><span class="c1"></span><span class="w">    </span><span class="n">parent_category_id</span><span class="w"> </span><span class="nb">BIGINT</span><span class="w"> </span><span class="c1">-- 顶级类目
</span><span class="c1"></span><span class="p">)</span><span class="w"> </span><span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;jdbc&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.url&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;jdbc:mysql://localhost:3306/flink&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.table&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;category&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.driver&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;com.mysql.jdbc.Driver&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.username&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;root&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.password&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;123456&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.lookup.cache.max-rows&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;5000&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.lookup.cache.ttl&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;10min&#39;</span><span class="w">
</span><span class="w"></span><span class="p">);</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>We also create an <code>Elasticsearch</code> table to store the category statistics.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">top_category</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="n">category_name</span><span class="w"> </span><span class="n">STRING</span><span class="p">,</span><span class="w">  </span><span class="c1">-- 类目名称
</span><span class="c1"></span><span class="w">    </span><span class="n">buy_cnt</span><span class="w"> </span><span class="nb">BIGINT</span><span class="w">  </span><span class="c1">-- 销量
</span><span class="c1"></span><span class="p">)</span><span class="w"> </span><span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;elasticsearch&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.version&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;6&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.hosts&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;http://localhost:9200&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.index&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;top_category&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;connector.document-type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;user_behavior&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;format.type&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;json&#39;</span><span class="p">,</span><span class="w">
</span><span class="w">    </span><span class="s1">&#39;update-mode&#39;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;upsert&#39;</span><span class="w">
</span><span class="w"></span><span class="p">);</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>In the first step we complete the class names through dimensional table association. We still use <code>CREATE VIEW</code> to register the query as a view and simplify the logic. The dimensional table association uses the <code>temporal join</code> syntax, see the documentation for more information: <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/streaming/joins.html#join-with-a-temporal-table">https://ci.apache.org/projects/flink/flink-docs-release-1.10/dev/table/streaming/joins.html#join-with-a-temporal-table</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">CREATE</span><span class="w"> </span><span class="k">VIEW</span><span class="w"> </span><span class="n">rich_user_behavior</span><span class="w"> </span><span class="k">AS</span><span class="w">
</span><span class="w"></span><span class="k">SELECT</span><span class="w"> </span><span class="n">U</span><span class="p">.</span><span class="n">user_id</span><span class="p">,</span><span class="w"> </span><span class="n">U</span><span class="p">.</span><span class="n">item_id</span><span class="p">,</span><span class="w"> </span><span class="n">U</span><span class="p">.</span><span class="n">behavior</span><span class="p">,</span><span class="w"> 
</span><span class="w">  </span><span class="k">CASE</span><span class="w"> </span><span class="k">C</span><span class="p">.</span><span class="n">parent_category_id</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;服饰鞋包&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;家装家饰&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;家电&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;美妆&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;母婴&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">6</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;3C数码&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">7</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;运动户外&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">WHEN</span><span class="w"> </span><span class="mi">8</span><span class="w"> </span><span class="k">THEN</span><span class="w"> </span><span class="s1">&#39;食品&#39;</span><span class="w">
</span><span class="w">    </span><span class="k">ELSE</span><span class="w"> </span><span class="s1">&#39;其他&#39;</span><span class="w">
</span><span class="w">  </span><span class="k">END</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">category_name</span><span class="w">
</span><span class="w"></span><span class="k">FROM</span><span class="w"> </span><span class="n">user_behavior</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="n">U</span><span class="w"> </span><span class="k">LEFT</span><span class="w"> </span><span class="k">JOIN</span><span class="w"> </span><span class="n">category_dim</span><span class="w"> </span><span class="k">FOR</span><span class="w"> </span><span class="n">SYSTEM_TIME</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">OF</span><span class="w"> </span><span class="n">U</span><span class="p">.</span><span class="n">proctime</span><span class="w"> </span><span class="k">AS</span><span class="w"> </span><span class="k">C</span><span class="w">
</span><span class="w"></span><span class="k">ON</span><span class="w"> </span><span class="n">U</span><span class="p">.</span><span class="n">category_id</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">C</span><span class="p">.</span><span class="n">sub_category_id</span><span class="p">;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>Finally, the number of events for <code>buy</code> is counted and written to <code>Elasticsearch</code>, grouped by category name.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">top_category</span><span class="w">
</span><span class="w"></span><span class="k">SELECT</span><span class="w"> </span><span class="n">category_name</span><span class="p">,</span><span class="w"> </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">buy_cnt</span><span class="w">
</span><span class="w"></span><span class="k">FROM</span><span class="w"> </span><span class="n">rich_user_behavior</span><span class="w">
</span><span class="w"></span><span class="k">WHERE</span><span class="w"> </span><span class="n">behavior</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;buy&#39;</span><span class="w">
</span><span class="w"></span><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">category_name</span><span class="p">;</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>After submitting the above query, create an <code>index pattern</code> for <code>top_category</code> in <code>Kibana</code>, then create a <code>Horizontal Bar</code> bar in <code>Dashboard</code>, select the <code>top_category</code> index, draw the category ranking according to the configuration in the screenshot below (left side), and save it.</p>
<p><img src="https://cdn.jsdelivr.net/gh/b0xt/sobyte-images/2021/06/29/01683ff8d2a54be8ba390ae7b8a250b6.png" alt=" "></p>
<p>As you can see, the volume of &ldquo;服饰鞋包&rdquo; is far ahead of other categories.</p>
<p><code>Kibana</code> also provides very rich graphing and visualization options, interested users can use <code>Flink SQL</code> to analyze the data in more dimensions, and use <code>Kibana</code> to display the visualization graph and observe the real-time changes of the graph data.</p>
<h2 id="ending">Ending</h2>
<p>In this article, we show how to use <code>Flink SQL</code> to integrate <code>Kafka</code>, <code>MySQL</code>, <code>Elasticsearch</code> and <code>Kibana</code> to quickly build a real-time analytics application. The whole process can be done without a single line of <code>Java/Scala</code> code, using <code>SQL</code> plain text. We hope this article will give readers an idea of the ease of use and power of <code>Flink SQL</code>, including easy connection to various external systems, native support for event time and chaotic data processing, dimensional table association, rich built-in functions, and more.</p>
<hr>
<p>Reference <code>http://wuchong.me/blog/2020/02/25/demo-building-real-time-application-with-flink-sql/</code></p>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/flink/">flink</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2021-06/introduction-to-spring-cloud-bus/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Introduction to Spring Cloud Bus</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/2021-06/pitfalls-of-os.popen-function-and-pipe-in-python/">
            <span class="next-text nav-default">Pitfalls of os.popen function and Pipe in Python</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://www.sobyte.net/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>

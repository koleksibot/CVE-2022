<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Kubernetes Microservices Best Practices - SoByte</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6356451834813761" crossorigin="anonymous"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-E8GRRGBTEZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-E8GRRGBTEZ');
</script>


<meta name="author" content="" /><meta name="description" content="This article introduces a set of &amp;ldquo;Kubernetes configuration&amp;rdquo; that I have summarized as my personal &amp;ldquo;best practices&amp;rdquo; in the process of using Kubernetes. Most of the content has been tested in an online environment, but there are a few parts that have only been simulated in my head, so please refer to them with caution. A few notes before reading. This document is quite long and includes a lot of" /><meta name="keywords" content="k8s, Best Practices" />






<meta name="generator" content="Hugo 0.92.2 with theme even" />


<link rel="canonical" href="https://www.sobyte.net/post/2022-01/kubernetes-best-practices/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Kubernetes Microservices Best Practices" />
<meta property="og:description" content="This article introduces a set of &ldquo;Kubernetes configuration&rdquo; that I have summarized as my personal &ldquo;best practices&rdquo; in the process of using Kubernetes. Most of the content has been tested in an online environment, but there are a few parts that have only been simulated in my head, so please refer to them with caution. A few notes before reading. This document is quite long and includes a lot of" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.sobyte.net/post/2022-01/kubernetes-best-practices/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-01-29T16:56:20+08:00" />
<meta property="article:modified_time" content="2022-01-29T16:56:20+08:00" />

<meta itemprop="name" content="Kubernetes Microservices Best Practices">
<meta itemprop="description" content="This article introduces a set of &ldquo;Kubernetes configuration&rdquo; that I have summarized as my personal &ldquo;best practices&rdquo; in the process of using Kubernetes. Most of the content has been tested in an online environment, but there are a few parts that have only been simulated in my head, so please refer to them with caution. A few notes before reading. This document is quite long and includes a lot of"><meta itemprop="datePublished" content="2022-01-29T16:56:20+08:00" />
<meta itemprop="dateModified" content="2022-01-29T16:56:20+08:00" />
<meta itemprop="wordCount" content="9032">
<meta itemprop="keywords" content="k8s," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Kubernetes Microservices Best Practices"/>
<meta name="twitter:description" content="This article introduces a set of &ldquo;Kubernetes configuration&rdquo; that I have summarized as my personal &ldquo;best practices&rdquo; in the process of using Kubernetes. Most of the content has been tested in an online environment, but there are a few parts that have only been simulated in my head, so please refer to them with caution. A few notes before reading. This document is quite long and includes a lot of"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">SoByte</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="/ukraine/">
        <li class="mobile-menu-item">UKRAINE</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">SoByte</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/ukraine/">UKRAINE</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Kubernetes Microservices Best Practices</h1>

      <div class="post-meta">
        <span class="post-time"> 2022-01-29 16:56:20 </span>
        <div class="post-category">
            <a href="/categories/tutorials/"> tutorials </a>
            </div>
          <span class="more-meta"> 9032 words </span>
          <span class="more-meta"> 19 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#0-examples">0. Examples</a></li>
        <li><a href="#1-graful-shutdown-and-502504-errors">1. Graful Shutdown and 502/504 errors</a>
          <ul>
            <li><a href="#what-if-my-service-is-also-using-sidecar-to-proxy-network-requests">What if my service is also using Sidecar to proxy network requests?</a></li>
            <li><a href="#reference">Reference</a></li>
          </ul>
        </li>
        <li><a href="#2-service-scaling-configuration---hpa">2. Service Scaling Configuration - HPA</a>
          <ul>
            <li><a href="#1-how-the-current-metric-value-is-calculated">1. How the current metric value is calculated</a></li>
            <li><a href="#3-what-is-the-appropriate-expectation-value-for-hpa">3. What is the appropriate expectation value for HPA</a></li>
            <li><a href="#4-frequently-asked-questions-about-hpa">4. Frequently Asked Questions about HPA</a></li>
            <li><a href="#5-hpa-cautions">5. HPA Cautions</a></li>
            <li><a href="#6-reference">6. Reference</a></li>
          </ul>
        </li>
        <li><a href="#3-node-maintenance-and-pod-interference-budget">3. Node maintenance and Pod interference budget</a>
          <ul>
            <li><a href="#considerations-for-using-percentages-in-pdb">Considerations for using percentages in PDB</a></li>
            <li><a href="#best-practices-deployment--hpa--poddisruptionbudget">Best Practices Deployment + HPA + PodDisruptionBudget</a></li>
          </ul>
        </li>
        <li><a href="#4-node-affinity-and-node-groups">4. Node Affinity and Node Groups</a>
          <ul>
            <li><a href="#1-node-affinity">1. node affinity</a></li>
            <li><a href="#2-pod-anti-affinity">2. Pod Anti-Affinity</a></li>
          </ul>
        </li>
        <li><a href="#5-pods-ready-probe-live-probe-and-startup-probe">5. Pod&rsquo;s Ready Probe, Live Probe and Startup Probe</a></li>
        <li><a href="#6-pod-security">6. Pod Security</a>
          <ul>
            <li><a href="#1-pod-securitycontext">1. Pod SecurityContext</a></li>
            <li><a href="#2-seccomp-security-compute-mode">2. seccomp: security compute mode</a></li>
          </ul>
        </li>
        <li><a href="#other-issues">Other issues</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>This article introduces a set of &ldquo;Kubernetes configuration&rdquo; that I have summarized as my personal &ldquo;best practices&rdquo; in the process of using Kubernetes. Most of the content has been tested in an online environment, but there are a few parts that have only been simulated in my head, so please refer to them with caution.</p>
<p>A few notes before reading.</p>
<ul>
<li>This document is quite long and includes a lot of content, so we recommend using it as a reference manual, first read it briefly with reference to the table of contents, and then read the relevant content in detail if needed.</li>
<li>This document requires a certain amount of Kubernetes foundation to understand, and if you have no practical experience, it may seem boring.
<ul>
<li>People with hands-on experience may have different opinions than I do, so feel free to comment.</li>
</ul>
</li>
</ul>
<p>I will update this document from time to time as appropriate.</p>
<h2 id="0-examples">0. Examples</h2>
<p>First of all, here are some of the premises that this paper adheres to, which only fit the scenarios I encountered and are flexible:</p>
<ul>
<li>Only stateless services are discussed here, stateful services are out of scope</li>
<li>Instead of using the rolling update capability of Deployment, we create a different Deployment + HPA + PodDisruptionBudget for each version of each service, this is to facilitate doing canary/grayscale releases</li>
<li>Our services may use IngressController / Service Mesh for load balancing of services, traffic slicing</li>
</ul>
<p>Here&rsquo;s a demo of Deployment + HPA + PodDisruptionBudget, which will be broken down later for more details.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">strategy</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RollingUpdate</span><span class="w">
</span><span class="w">    </span><span class="c"># 因为服务的每个版本都使用各自的 Deployment，服务更新时其实是用不上这里的滚动更新策略的</span><span class="w">
</span><span class="w">    </span><span class="c"># 这个配置应该只在 SRE 手动修改 Deployment 配置时才会生效（通常不应该发生这种事）</span><span class="w">
</span><span class="w">    </span><span class="nt">rollingUpdate</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">maxSurge</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="l">% </span><span class="w"> </span><span class="c"># 滚动更新时，每次最多更新 10% 的 Pods</span><span class="w">
</span><span class="w">      </span><span class="nt">maxUnavailable</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c"># 滚动更新时，不允许出现不可用的 Pods，也就是说始终要维持 3 个可用副本</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v3</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">        </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v3</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">affinity</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">podAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w"> </span><span class="c"># 非强制性条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">100</span><span class="w">  </span><span class="c"># weight 用于为节点评分，会优先选择评分最高的节点（只有一条规则的情况下，这个值没啥意义）</span><span class="w">
</span><span class="w">            </span><span class="nt">podAffinityTerm</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">                </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">my-app</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">v3</span><span class="w">
</span><span class="w">              </span><span class="c"># pod 尽量使用同一种节点类型，也就是尽量保证节点的性能一致</span><span class="w">
</span><span class="w">              </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">node.kubernetes.io/instance-type</span><span class="w">
</span><span class="w">        </span><span class="nt">podAntiAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w"> </span><span class="c"># 非强制性条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">100</span><span class="w">  </span><span class="c"># weight 用于为节点评分，会优先选择评分最高的节点（只有一条规则的情况下，这个值没啥意义）</span><span class="w">
</span><span class="w">            </span><span class="nt">podAffinityTerm</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">                </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">my-app</span><span class="w">
</span><span class="w">                </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                  </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                  </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                  </span>- <span class="l">v3</span><span class="w">
</span><span class="w">              </span><span class="c"># 将 pod 尽量打散在多个可用区</span><span class="w">
</span><span class="w">              </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">topology.kubernetes.io/zone</span><span class="w">
</span><span class="w">          </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">  </span><span class="c"># 强制性要求（这个建议按需添加）</span><span class="w">
</span><span class="w">          </span><span class="c"># 注意这个没有 weights，必须满足列表中的所有条件</span><span class="w">
</span><span class="w">          </span>- <span class="nt">labelSelector</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">app</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">my-app</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">version</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">v3</span><span class="w">
</span><span class="w">            </span><span class="c"># Pod 必须运行在不同的节点上</span><span class="w">
</span><span class="w">            </span><span class="nt">topologyKey</span><span class="p">:</span><span class="w"> </span><span class="l">kubernetes.io/hostname</span><span class="w">
</span><span class="w">      </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="c"># runAsUser: 1000  # 设定用户</span><span class="w">
</span><span class="w">        </span><span class="c"># runAsGroup: 1000  # 设定用户组</span><span class="w">
</span><span class="w">        </span><span class="nt">runAsNonRoot</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># Pod 必须以非 root 用户运行</span><span class="w">
</span><span class="w">        </span><span class="nt">seccompProfile</span><span class="p">:</span><span class="w">  </span><span class="c"># security compute mode</span><span class="w">
</span><span class="w">          </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RuntimeDefault</span><span class="w">
</span><span class="w">      </span><span class="nt">nodeSelector</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">eks.amazonaws.com/nodegroup</span><span class="p">:</span><span class="w"> </span><span class="l">common </span><span class="w"> </span><span class="c"># 使用专用节点组，如果希望使用多个节点组，可改用节点亲和性</span><span class="w">
</span><span class="w">      </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">tmp-dir</span><span class="w">
</span><span class="w">        </span><span class="nt">emptyDir</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">my-app:v3 </span><span class="w"> </span><span class="c"># 建议使用私有镜像仓库，规避 docker.io 的镜像拉取限制</span><span class="w">
</span><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent</span><span class="w">
</span><span class="w">        </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span><span class="w">        </span>- <span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="l">/tmp</span><span class="w">
</span><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">tmp-dir</span><span class="w">
</span><span class="w">        </span><span class="nt">lifecycle</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">preStop</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">exec</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="l">/bin/sh</span><span class="w">
</span><span class="w">              </span>- -<span class="l">c</span><span class="w">
</span><span class="w">              </span>- <span class="s2">&#34;while [ $(netstat -plunt | grep tcp | wc -l | xargs) -ne 0 ]; do sleep 1; done&#34;</span><span class="w">
</span><span class="w">        </span><span class="nt">resources</span><span class="p">:</span><span class="w">  </span><span class="c"># 资源请求与限制</span><span class="w">
</span><span class="w">          </span><span class="c"># 对于核心服务，建议设置 requests = limits，避免资源竞争</span><span class="w">
</span><span class="w">          </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="c"># HPA 会使用 requests 计算资源利用率</span><span class="w">
</span><span class="w">            </span><span class="c"># 建议将 requests 设为服务正常状态下的 CPU 使用率，HPA 的目前指标设为 80%</span><span class="w">
</span><span class="w">            </span><span class="c"># 所有容器的 requests 总量不建议为 2c/4G 4c/8G 等常见值，因为节点通常也是这个配置，这会导致 Pod 只能调度到更大的节点上，适当调小 requests 等扩充可用的节点类型，从而扩充节点池。 </span><span class="w">
</span><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">1000m</span><span class="w">
</span><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span><span class="w">          </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="c"># limits - requests 为允许超卖的资源量，建议为 requests 的 1 到 2 倍，酌情配置。</span><span class="w">
</span><span class="w">            </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">1000m</span><span class="w">
</span><span class="w">            </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span><span class="w">        </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="c"># 将容器层设为只读，防止容器文件被篡改</span><span class="w">
</span><span class="w">          </span><span class="c">## 如果需要写入临时文件，建议额外挂载 emptyDir 来提供可读写的数据卷</span><span class="w">
</span><span class="w">          </span><span class="nt">readOnlyRootFilesystem</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">          </span><span class="c"># 禁止 Pod 做任何权限提升</span><span class="w">
</span><span class="w">          </span><span class="nt">allowPrivilegeEscalation</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span><span class="w">          </span><span class="nt">capabilities</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="c"># drop ALL 的权限比较严格，可按需修改</span><span class="w">
</span><span class="w">            </span><span class="nt">drop</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">ALL</span><span class="w">
</span><span class="w">        </span><span class="nt">startupProbe</span><span class="p">:</span><span class="w">  </span><span class="c"># 要求 kubernetes 1.18+</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 直接使用健康检查接口即可</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">20</span><span class="w">  </span><span class="c"># 最多提供给服务 5s * 20 的启动时间</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># spring 的通用健康检查路径</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="c"># Readiness probes are very important for a RollingUpdate to work properly,</span><span class="w">
</span><span class="w">        </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 简单起见可直接使用 livenessProbe 相同的接口，当然也可额外定义</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w"></span><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">autoscaling/v2beta2</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HorizontalPodAutoscaler</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Resource</span><span class="w">
</span><span class="w">    </span><span class="nt">resource</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cpu</span><span class="w">
</span><span class="w">      </span><span class="nt">target</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Utilization</span><span class="w">
</span><span class="w">        </span><span class="nt">averageUtilization</span><span class="p">:</span><span class="w"> </span><span class="m">70</span><span class="w">
</span><span class="w"></span><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">policy/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PodDisruptionBudget</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">minAvailable</span><span class="p">:</span><span class="w"> </span><span class="m">75</span><span class="l">%</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l">v3</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h2 id="1-graful-shutdown-and-502504-errors">1. Graful Shutdown and 502/504 errors</h2>
<p>If a Pod is processing a large number of requests (e.g. 1000 QPS+) and is rescheduled due to a node failure or a &ldquo;bid node&rdquo; being recalled, you may observe a small number of 502/504s during the period when the container is terminated.</p>
<p>To understand this, you need to first understand the process of terminating a Pod.</p>
<ol>
<li>the Pod&rsquo;s status is set to <code>Terminating</code> and (almost) simultaneously the Pod is removed from all associated Service Endpoints</li>
<li>the <code>preStop</code> hook is executed, either as a command, or as an http call to the container in the Pod
<ol>
<li>consider using <code>preStop</code> if your application is unable to exit gracefully when it receives a SIGTERM signal</li>
<li>if it&rsquo;s too much trouble to make the program support graceful exit itself, <code>preStop</code> is a good way to achieve it</li>
</ol>
</li>
<li>send SIGTERM to all containers in the Pod</li>
<li>continue waiting until the time set by <code>spec.terminationGracePeriodSeconds</code> is exceeded, the default value is 30s
<ol>
<li>Note that this graceful exit wait is synchronized with <code>preStop</code>! And it doesn&rsquo;t wait for <code>preStop</code> to finish either!</li>
</ol>
</li>
<li>If the container does not stop after <code>spec.terminationGracePeriodSeconds</code>, k8s will send a SIGKILL signal to the container.</li>
<li>After all processes are terminated, the entire Pod is completely cleaned up</li>
</ol>
<p><strong>Note</strong>: 1 and 2 jobs happen asynchronously, so there may be a situation where &ldquo;Pod is still in Service Endpoints, but <code>preStop</code> has already been executed&rdquo;, and we need to take into account the occurrence of this situation.</p>
<p>After understanding the above flow, we can analyze the reasons for the appearance of two error codes.</p>
<ul>
<li>502: The application terminated directly after receiving the SIGTERM signal, causing some of the requests that have not yet been processed to be interrupted directly, and the proxy layer returned 502 to indicate this situation</li>
<li>504: Service Endpoints removal is not timely enough, after the Pod has been terminated, there are still individual requests are routed to the Pod, and do not get a response resulting in 504</li>
</ul>
<p>The usual solution is to add a 15s wait time to the Pod&rsquo;s <code>preStop</code> step. The rationale is that when the Pod processes the terminating state, it is removed from the Service Endpoints and no new requests are made. Waiting 15s in <code>preStop</code> basically ensures that all requests are processed before the container dies (in general, most requests are processed in 300ms or less).</p>
<p>A simple example, which makes the Pod always wait 15s before sending a SIGTERM signal to the container when it is terminated, is as follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">    </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="c"># 添加下面这部分</span><span class="w">
</span><span class="w">      </span><span class="nt">lifecycle</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">preStop</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">exec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">/bin/sleep</span><span class="w">
</span><span class="w">            </span>- <span class="s2">&#34;15&#34;</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>A better solution is to just wait until all tcp connections are closed (requires netstat in the image)</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">    </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">      </span><span class="c"># 添加下面这部分</span><span class="w">
</span><span class="w">      </span><span class="nt">lifecycle</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">preStop</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">exec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">/bin/sh</span><span class="w">
</span><span class="w">            </span>- -<span class="l">c</span><span class="w">
</span><span class="w">            </span>- <span class="s2">&#34;while [ $(netstat -plunt | grep tcp | wc -l | xargs) -ne 0 ]; do sleep 1; done&#34;</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="what-if-my-service-is-also-using-sidecar-to-proxy-network-requests">What if my service is also using Sidecar to proxy network requests?</h3>
<p>Using the service grid Istio as an example, the 502/504 issue gets a little more complicated when Envoy is proxying Pod traffic - also consider the order in which Sidecar closes with the main container.</p>
<ul>
<li>If a new request comes in after Envoy has been shut down, it will result in a 504 (no one will respond to the request)
<ul>
<li>So Envoy should be shut down at least 3s after Terminating to make sure the Istio grid configuration is fully updated</li>
</ul>
</li>
<li>If the main container is shut down before Envoy is stopped, and then a new request comes in, Envoy will be unable to connect to upstream resulting in 503
<ul>
<li>So it is also better to close the main container after Terminating at least 3s.</li>
</ul>
</li>
<li>If Envoy or one of the main containers stops while the main container is still processing the legacy requests, it will be disconnected directly because of tcp connection resulting in 502
<ul>
<li>Therefore Envoy must be closed after the main container has finished processing legacy requests (that is, when there is no tcp connection)</li>
</ul>
</li>
</ul>
<p>So to summarize: Envoy and the main container&rsquo;s <code>preStop</code> must be set to at least 3s, and can be closed only when there is no tcp connection, to avoid 502/503/504.</p>
<p>The modification method of the main container has been written in the previous article, the following describes the modification method of Envoy.</p>
<p>Like the main container, Envoy can also add <code>preStop</code> directly, modify <code>istio-sidecar-injector</code> the <code>configmap</code>, and add the preStop sleep command in sidecar:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">    </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">istio-proxy</span><span class="w">
</span><span class="w">      </span><span class="c"># 添加下面这部分</span><span class="w">
</span><span class="w">      </span><span class="nt">lifecycle</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">preStop</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">exec</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">command</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="l">/bin/sh</span><span class="w">
</span><span class="w">            </span>- -<span class="l">c</span><span class="w">
</span><span class="w">            </span>- <span class="s2">&#34;while [ $(netstat -plunt | grep tcp | grep -v envoy | wc -l | xargs) -ne 0 ]; do sleep 1; done&#34;</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="reference">Reference</h3>
<ul>
<li><a href="https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-terminating-with-grace">Kubernetes best practices: terminating with grace</a></li>
<li><a href="https://medium.com/flant-com/kubernetes-graceful-shutdown-nginx-php-fpm-d5ab266963c2">Graceful shutdown in Kubernetes is not always trivial</a></li>
</ul>
<h2 id="2-service-scaling-configuration---hpa">2. Service Scaling Configuration - HPA</h2>
<p>Kubernetes officially supports Pod CPU-based scaling, which is the most widely used scaling metric and requires the deployment of <a href="https://github.com/kubernetes-sigs/metrics-server">metrics-server</a> to be available.</p>
<p>To start with, review the example of scaling based on Pod CPU usage given earlier.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">autoscaling/v2beta2 </span><span class="w"> </span><span class="c"># k8s 1.23+ 此 API 已经 GA</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HorizontalPodAutoscaler</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">my-app</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Resource</span><span class="w">
</span><span class="w">    </span><span class="nt">resource</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cpu</span><span class="w">
</span><span class="w">      </span><span class="nt">target</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Utilization</span><span class="w">
</span><span class="w">        </span><span class="nt">averageUtilization</span><span class="p">:</span><span class="w"> </span><span class="m">70</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="1-how-the-current-metric-value-is-calculated">1. How the current metric value is calculated</h3>
<p>To summarize in advance: the metric of each <strong>Pod is the sum of all container metrics</strong>, and if calculating the percentage, divide it by the requests of the Pod.</p>
<p>HPA uses the Pod&rsquo;s current metrics for calculation by default, taking CPU usage as an example, its calculation formula is.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">「Pod 的 CPU 使用率」<span class="o">=</span> 100% * 「所有 Container 的 CPU 用量之和」/「所有 Container 的 CPU requests 之和」
</code></pre></td></tr></table>
</div>
</div><p>Note that the denominator is the total number of requests, not the limits.</p>
<h4 id="11-problems-and-solutions">1.1 Problems and solutions</h4>
<p>This is not a problem when the Pod has only one container, but it is a problem when the Pod is injected with sidecar like envoy.</p>
<p>This is because Istio&rsquo;s Sidecar requests default to <code>100m</code> which is 0.1 cores. In the untuned case, the actual sidecar usage can easily go up to 0.2-0.4 cores when the service load is high. Substituting these two values into the previous equation, we find that <strong>for services with high QPS, after adding Sidecar, the &ldquo;CPU utilization of Pod&rdquo; may be higher than the &ldquo;CPU utilization of application container &ldquo;</strong>, resulting in unnecessary scaling.</p>
<p>Even if we use &ldquo;CPU utilization of Pods&rdquo; instead of percentage to scale up and down, it does not solve this problem.</p>
<p>Solutions.</p>
<ul>
<li>Method 1: Set different requests/limits for each service&rsquo;s sidecar according to each service&rsquo;s CPU usage.
<ul>
<li>I think this solution is too troublesome.</li>
</ul>
</li>
<li>Method 2: Use a third-party component like KEDA to get the CPU utilization of the application (excluding Sidecar) and use it to scale up and down.</li>
<li>Method 3: Use the alpha feature provided by k8s 1.20: <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#container-resource-metrics">Container Resourse Metrics</a>.</li>
</ul>
<h4 id="2-hpas-expansion-and-contraction-algorithm">2. HPA&rsquo;s expansion and contraction algorithm</h4>
<p>It is well understood when the HPA will be expanded. However, there is some confusion about HPA&rsquo;s scaling strategy, which is briefly analyzed below.</p>
<ol>
<li>
<p>HPA&rsquo;s &ldquo;target metrics&rdquo; can be used in two forms: absolute metrics and resource utilization.</p>
<ul>
<li>Absolute metrics: CPU, for example, refers to CPU usage</li>
<li>Resource utilization (resource usage/resource request * 100%): When a Pod sets up a resource request, you can use the resource utilization to scale the Pod. 2.</li>
</ul>
</li>
<li>
<p>The &ldquo;current metric&rdquo; of HPA is the average of all Pods over a period of time, not the peak.</p>
</li>
</ol>
<p>The scaling algorithm of HPA is.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text">期望副本数 = ceil[当前副本数 * ( 当前指标 / 目标指标 )]
</code></pre></td></tr></table>
</div>
</div><p>As you can see from the parameters above.</p>
<ol>
<li>whenever the <code>current indicator</code> exceeds the target indicator, the expansion will definitely happen.</li>
<li>the <code>current indicator / target indicator</code> has to be small enough to trigger the shrinkage.
For example, in the case of a double copy, the above ratio must be less than or equal to 1/2 before scaling down to a single copy.
2. In the case of three copies, the threshold for the above ratio is 2/3.
3. The threshold for five copies is 4/5, for 100 copies the threshold is 99/100, and so on.
4. If the `Current Target/Target Target' drops from 1 to 0.5, the number of copies will be halved. (Although it is said that the more copies there are, the less likely such a large change will occur.)</li>
<li>the larger the value of <code>Current Replica Count / Target Indicator</code>, the greater the impact of fluctuations in the <code>Current Indicator</code> on the <code>Desired Replica Count</code>.</li>
</ol>
<p>In order to prevent over-sensitive expansion and contraction, it also has several latency-related parameters.</p>
<ol>
<li>HPA Loop delay: default 15 seconds, HPA scan is performed every 15 seconds.</li>
<li><code>--horizontal-pod-autoscaler-cpu-initialization-period</code>:</li>
<li>shrink-capacity cooling time: default 5 minutes.</li>
</ol>
<h3 id="3-what-is-the-appropriate-expectation-value-for-hpa">3. What is the appropriate expectation value for HPA</h3>
<p>This needs to be analyzed on a case-by-case basis for each service.</p>
<p>Take the most common scaling by CPU value as an example</p>
<ul>
<li>Core services
<ul>
<li>requests/limits value: It is recommended to set it equal to ensure that the <a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/">quality of service level</a> is Guaranteed
<ul>
<li>Note that CPU and Memory limits are different, CPU is really limited, while Memory is OOMKilled when it is exceeded.</li>
<li>k8s has been using cgroups v1 ( <code>cpu_shares</code> / <code>memory.limit_in_bytes</code> ) to limit cpu/memory, but for <code>Guaranteed</code> Pods, memory is not fully reserved, and resource contention is always possible. 1.22 has alpha feature to use cgroups v2, so keep an eye on that.</li>
</ul>
</li>
<li>HPA: Generally speaking, an expectation of 60% to 70% may be appropriate, and a minimum number of copies is recommended to be set to 2 - 5. (FYI)</li>
<li>PodDisruptionBudget: It is recommended to set the PDB according to the service robustness and HPA expectation, which will be introduced in detail later, so we will skip it here first.</li>
</ul>
</li>
<li>Non-core services
<ul>
<li>requests/limits value: it is recommended that requests be set to 0.6 - 0.9 times the limits (for reference only), corresponding to the quality of service level of Burstable
<ul>
<li>The main consideration is that many non-core services have a very low load and do not run as high as the limits, so lowering requests can improve cluster resource utilization without compromising service stability.</li>
</ul>
</li>
<li>HPA: Because requests are reduced, and HPA is calculated using requests as 100% utilization, we can increase the expected value of HPA (if we use the percentage as the expected value), such as 80% to 90%, and the minimum number of copies is recommended to be set to 1 - 3. (For reference only)</li>
<li>PodDisruptionBudget: non-core services, to ensure that the minimum number of copies of 1 on the line.</li>
</ul>
</li>
</ul>
<h3 id="4-frequently-asked-questions-about-hpa">4. Frequently Asked Questions about HPA</h3>
<h4 id="41-pod-scaling---warm-up-pitfalls">4.1. Pod scaling - warm-up pitfalls</h4>
<blockquote>
<p>Warm-up: For languages like Java/C# that run on a virtual machine, the first time you use certain features, you need to initialize some resources, such as &ldquo;JIT compile on the fly&rdquo;. If the code also applies dynamic class loading or other features, it is likely that the microservice will be particularly slow to respond when some APIs are called for the first time (to dynamically compile the class). Therefore, Pods need to &ldquo;slow_start&rdquo; these interfaces and initialize the resources they need in advance before providing services.</p>
</blockquote>
<p>In the case of high load, HPA will automatically expand the capacity. However, if the scaled Pod needs to be warmed up, it may encounter the &ldquo;warm-up trap&rdquo;.</p>
<p>When there is a large number of users accessing the Pod, the request will be &ldquo;stuck&rdquo; as long as it is forwarded to the newly created Pod, regardless of the load balancing policy used. If the request speed is too fast, the more requests are &ldquo;stuck&rdquo; at the moment the Pod starts up, which will cause the new Pod to collapse due to overstress. Then the Pod is overwhelmed as soon as it restarts and enters the CrashLoopBackoff loop.</p>
<p>The effect is even more pronounced when using multithreading for load testing: with 50 threads requesting non-stop, the response time of other Pods is &ldquo;milliseconds&rdquo;, while the first response of a new Pod is &ldquo;seconds&rdquo;. Almost instantly, all 50 threads will be trapped in the new Pod. The newly created Pod may be particularly vulnerable at the moment of startup, and the 50 concurrent requests can overwhelm it instantly. Then the Pod is crushed as soon as it restarts and enters the CrashLoopBackoff loop.</p>
<p><strong>Solution</strong>.</p>
<p>This can be solved at the &ldquo;application level&rdquo; by</p>
<ol>
<li>inside the back-end controller that starts the probe API, call all interfaces that need to be warmed up in turn or otherwise, and initialize all resources in advance.
In the controller that starts the probe, you can call its own interface via the <code>localhost</code> loopback address.</li>
<li>Use the &ldquo;AOT pre-compilation&rdquo; technique: preheating is usually a problem caused by &ldquo;JIT just-in-time compilation&rdquo;, which is compiled when it is needed. AOT is pre-compiled and compiled before use, so AOT can solve the problem of pre-heating.</li>
</ol>
<p>It can also be solved at the &ldquo;infrastructure level&rdquo;.</p>
<ol>
<li>Like AWS ALB TargetGroup and other cloud service providers' ALB services, you can usually set <code>slow_start</code> time, that is, for new instances, use a certain amount of time to slowly cut the traffic over, and finally reach the expected load balancing state. This can solve the service warm-up problem. 2.</li>
<li>Envoy also supports <code>slow_start</code> mode, which supports to slowly load the traffic to the new instance within a set time window to achieve the warm-up effect.</li>
</ol>
<h4 id="42-hpa-scaling-is-too-sensitive-and-leads-to-pod-oscillation">4.2. HPA scaling is too sensitive and leads to Pod oscillation</h4>
<p>In general, the majority of the load on EKS should be scaled up or down using CPUs. This is because the CPU is usually a good reflection of the load on the service</p>
<p>However, some services have other factors that affect CPU usage that make scaling with CPU less reliable, such as</p>
<ul>
<li>Some Java services have large heap memory settings and long GC pause settings, so memory GC can cause intermittent CPU spikes and CPU monitoring can have a lot of spikes.</li>
<li>Some services have timed tasks, and the CPU will go up when the timed tasks run, but this is not related to the QPS of the service.</li>
<li>Some services may immediately be in a high state as soon as the CPU is running, and it may want to use other business-side metrics for scaling instead of CPU.</li>
</ul>
<p>Because of the above problem, using CPU scaling may cause the service to scale up and down frequently, or infinitely. Some services (such as our &ldquo;recommended services&rdquo;) are sensitive to both &ldquo;scaling up&rdquo; and &ldquo;scaling down&rdquo;, and each scaling up and down will cause service availability jitter.</p>
<p>For such services, HPA has these tuning strategies.</p>
<ul>
<li>Choose to use relatively smooth metrics like <strong>QPS</strong> for scaling up and scaling down without the interference of GC, which requires community components like KEDA.</li>
<li>For kubernetes 1.18+, you can directly use HPA&rsquo;s <code>behavior.scaleDown</code> and <code>behavior.scaleUp</code> parameters to control the maximum number of pods or ratio for each scaling. An example is as follows.</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nn">---</span><span class="w">
</span><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">autoscaling/v2beta2</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">HorizontalPodAutoscaler</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">default</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">scaleTargetRef</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w">    </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo</span><span class="w">
</span><span class="w">  </span><span class="nt">minReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">maxReplicas</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">
</span><span class="w">  </span><span class="nt">metrics</span><span class="p">:</span><span class="w">
</span><span class="w">  </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Resource</span><span class="w">
</span><span class="w">    </span><span class="nt">resource</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cpu</span><span class="w">
</span><span class="w">      </span><span class="nt">target</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Utilization</span><span class="w">
</span><span class="w">        </span><span class="nt">averageUtilization</span><span class="p">:</span><span class="w"> </span><span class="m">50</span><span class="w">  </span><span class="c"># 期望的 CPU 平均值</span><span class="w">
</span><span class="w">  </span><span class="nt">behavior</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">scaleUp</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">stabilizationWindowSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c"># 默认为 0，只使用当前值进行扩缩容</span><span class="w">
</span><span class="w">      </span><span class="nt">policies</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">180</span><span class="w">  </span><span class="c"># 每 3 分钟最多扩容 5% 的 Pods</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Percent</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">      </span>- <span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">60</span><span class="w">  </span><span class="c"># 每分钟最多扩容 1 个 Pod，扩的慢一点主要是为了一个个地预热，避免一次扩容太多未预热的 Pods 导致服务可用率剧烈抖动</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Pods</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">      </span><span class="nt">selectPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">Min </span><span class="w"> </span><span class="c"># 选择最小的策略</span><span class="w">
</span><span class="w">    </span><span class="c"># 以下的一切配置，都是为了更平滑地缩容</span><span class="w">
</span><span class="w">    </span><span class="nt">scaleDown</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">stabilizationWindowSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">600</span><span class="w">  </span><span class="c"># 使用过去 10 mins 的最大 cpu 值进行缩容计算，避免过快缩容</span><span class="w">
</span><span class="w">      </span><span class="nt">policies</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Percent </span><span class="w"> </span><span class="c"># 每 3 mins 最多缩容 `ceil[当前副本数 * 5%]` 个 pod（20 个 pod 以内，一次只缩容 1 个 pod）</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">        </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">180</span><span class="w">
</span><span class="w">      </span>- <span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Pods </span><span class="w"> </span><span class="c"># 每 1 mins 最多缩容 1 个 pod</span><span class="w">
</span><span class="w">        </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">60</span><span class="w">
</span><span class="w">      </span><span class="nt">selectPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">Min </span><span class="w"> </span><span class="c"># 上面的 policies 列表，只生效其中最小的值作为缩容限制（保证平滑缩容）</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>For the problem of not smooth scaling, consider providing a feature similar to AWS ALB TargetGroup <code>slow_start</code> to slowly cut the traffic to the new Pod when scaling to achieve preheat services (JVM preheat and local cache preheat), so that a better smooth scaling effect can be achieved.</p>
<h3 id="5-hpa-cautions">5. HPA Cautions</h3>
<p>Note that kubectl versions below 1.23 use <code>hpa.v1.autoscaling</code> to query the HPA configuration by default, and <code>v2beta2</code> related parameters are encoded in <code>metadata.annotations</code>.</p>
<p>For example, <code>behavior</code> is encoded in the value corresponding to the key <code>autoscaling.alpha.kubernetes.io/behavior</code>.</p>
<p>So if you are using the v2beta2 HPA, be sure to explicitly specify that you are using the <code>v2beta2</code> version of the HPA.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">kubectl get hpa.v2beta2.autoscaling
</code></pre></td></tr></table>
</div>
</div><p>Otherwise, accidentally touching some parameters encoded in <code>annotations</code> may have unexpected effects, or even crash the control panel&hellip; like this issue: <a href="https://github.com/kubernetes/kubernetes/issues/107038">Nil pointer dereference in KCM after v1 HPA patch request</a></p>
<h3 id="6-reference">6. Reference</h3>
<ul>
<li><a href="https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale/">Pod 水平自动伸缩 - Kubernetes Docs</a></li>
<li><a href="https://kubernetes.io/zh/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">Horizontal Pod Autoscaler演练 - Kubernetes Docs</a></li>
</ul>
<h2 id="3-node-maintenance-and-pod-interference-budget">3. Node maintenance and Pod interference budget</h2>
<p><a href="https://kubernetes.io/zh/docs/tasks/run-application/configure-pdb/">Node Maintenance and Pod Interference Budget</a></p>
<p>When we evict containers from a node via <code>kubectl drain</code>, kubernetes will do the Pod eviction based on the Pod&rsquo;s <code>PodDistruptionBuget</code>.</p>
<p>If you don&rsquo;t set any explicit PodDistruptionBuget, the Pod will simply be killed and rescheduled on another node, <strong>which may cause service interruptions!</strong></p>
<p>PDB is a separate CR custom resource, example is as follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">policy/v1beta1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PodDisruptionBudget</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo-pdb</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># 如果不满足 PDB，Pod 驱逐将会失败！</span><span class="w">
</span><span class="w">  </span><span class="nt">minAvailable</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">      </span><span class="c"># 最少也要维持一个 Pod 可用</span><span class="w">
</span><span class="w"></span><span class="c">#   maxUnavailable: 1  # 最大不可用的 Pod 数，与 minAvailable 不能同时配置！二选一</span><span class="w">
</span><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">podinfo</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>If the Pod does not satisfy the PDB when performing node maintenance (kubectl drain), the drain will fail, example.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">&gt; kubectl drain node-205 --ignore-daemonsets --delete-local-data
node/node-205 cordoned
WARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-nfhj7, kube-system/kube-proxy-94dz5
evicting pod default/podinfo-7c84d8c94d-h9brq
evicting pod default/podinfo-7c84d8c94d-gw6qf
error when evicting pod <span class="s2">&#34;podinfo-7c84d8c94d-h9brq&#34;</span> <span class="o">(</span>will retry after 5s<span class="o">)</span>: Cannot evict pod as it would violate the pod<span class="s1">&#39;s disruption budget.
</span><span class="s1">evicting pod default/podinfo-7c84d8c94d-h9brq
</span><span class="s1">error when evicting pod &#34;podinfo-7c84d8c94d-h9brq&#34; (will retry after 5s): Cannot evict pod as it would violate the pod&#39;</span>s disruption budget.
evicting pod default/podinfo-7c84d8c94d-h9brq
error when evicting pod <span class="s2">&#34;podinfo-7c84d8c94d-h9brq&#34;</span> <span class="o">(</span>will retry after 5s<span class="o">)</span>: Cannot evict pod as it would violate the pod<span class="err">&#39;</span>s disruption budget.
evicting pod default/podinfo-7c84d8c94d-h9brq
pod/podinfo-7c84d8c94d-gw6qf evicted
pod/podinfo-7c84d8c94d-h9brq evicted
node/node-205 evicted

</code></pre></td></tr></table>
</div>
</div><p>In the example above, there are two copies of podinfo, both running on node-205. I set the interference budget PDB <code>minAvailable: 1</code> for it.</p>
<p>Then when I use <code>kubectl drain</code> to evict the Pod, one of the Pods is evicted immediately, while the other Pod keeps failing to evict for about 15 seconds. Because the first Pod has not finished starting on the new node, it does not meet the condition of interfering with the budget PDB <code>minAvailable: 1</code>.</p>
<p>After about 15 seconds, the first Pod to be expelled is started on the new node and the other Pod meets the PDB so it is finally expelled as well. This completes the drain operation of a node.</p>
<blockquote>
<p>PodDisruptionBudget is also considered when scaling down nodes in cluster node scaling components such as ClusterAutoscaler. If your cluster uses a component such as ClusterAutoscaler that dynamically scales up and down nodes, it is highly recommended to set PodDisruptionBudget for all services.</p>
</blockquote>
<h3 id="considerations-for-using-percentages-in-pdb">Considerations for using percentages in PDB</h3>
<p>When using percentages, the calculated number of instances is rounded up, which can cause two phenomena.</p>
<ul>
<li>If you use <code>minAvailable</code>, a small number of instances may cause ALLOWED DISRUPTIONS to be 0</li>
<li>If <code>maxUnavailable</code> is used, since it is rounded up, the value of ALLOWED DISRUPTIONS must not be lower than 1</li>
</ul>
<p>So for eviction purposes, if you have at least 2-3 instances of your service, it is recommended to use the percentage configuration <code>maxUnavailable</code> in the PDB instead of <code>minAvailable</code> .</p>
<h3 id="best-practices-deployment--hpa--poddisruptionbudget">Best Practices Deployment + HPA + PodDisruptionBudget</h3>
<p>In general, each version of a service should contain the following three resources.</p>
<ul>
<li>Deployment: The Pods that manage the service itself</li>
<li>HPA: Responsible for scaling up and down Pods, usually using CPU metrics for scaling up and down</li>
<li>PodDisruptionBudget(PDB): It is recommended to set the PDB according to the target value of HPA.
<ul>
<li>For example, if the HPA CPU target is 60%, consider setting PDB <code>minAvailable=65%</code> to ensure that at least 65% of Pods are available. This way, theoretically, the QPS will not be avalanched evenly over the remaining 65% of Pods in the extreme case (assuming a perfectly linear relationship between QPS and CPU here)</li>
</ul>
</li>
</ul>
<h2 id="4-node-affinity-and-node-groups">4. Node Affinity and Node Groups</h2>
<p>We a cluster, usually use different tags to classify node groups, for example, kubernetes automatically generates some node tags.</p>
<ul>
<li><code>kubernetes.io/os</code> : <code>linux</code> is usually used</li>
<li><code>kubernetes.io/arch</code> : <code>amd64</code> , <code>arm64</code></li>
<li><code>topology.kubernetes.io/region</code> and <code>topology.kubernetes.io/zone</code> : regions and availability zones for cloud services</li>
</ul>
<p>We use <code>node affinity</code> and <code>Pod anti-affinity</code> more often, and the other two policies are used as appropriate.</p>
<h3 id="1-node-affinity">1. node affinity</h3>
<p>If you are using aws, then aws has some custom node tags.</p>
<ul>
<li><code>eks.amazonaws.com/nodegroup</code> : the name of the aws eks node group, the same node group uses the same aws ec2 instance template
<ul>
<li>e.g. arm64 node group, amd64/x64 node group</li>
<li>node groups with high memory ratio such as m-series instances, node groups with high computational performance such as c-series</li>
<li>bid instance node group: this saves money, but is very dynamic and can be recycled at any time</li>
<li>Pay-per-volume node group: this is expensive but stable instances.</li>
</ul>
</li>
</ul>
<p>Suppose you want to give preference to bid instances to run your Pod, and if the bid instances are temporarily full, choose pay-per-use instances. Then <code>nodeSelector</code> won&rsquo;t meet your needs and you need to use <code>nodeAffinity</code>, as in the following example:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">xxx</span><span class="w">
</span><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">xxx</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># ...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">affinity</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">nodeAffinity</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="c"># 优先选择 spot-group-c 的节点</span><span class="w">
</span><span class="w">          </span><span class="nt">preferredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">
</span><span class="w">          </span>- <span class="nt">preference</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">eks.amazonaws.com/nodegroup</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">spot-group-c</span><span class="w">
</span><span class="w">            </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">  </span><span class="c"># weight 用于为节点评分，会优先选择评分最高的节点</span><span class="w">
</span><span class="w">          </span>- <span class="nt">preference</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="c"># 优先选择 aws c6i 的机器</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">node.kubernetes.io/instance-type</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.2xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.4xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c6i.8xlarge&#34;</span><span class="w">
</span><span class="w">            </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">70</span><span class="w">
</span><span class="w">          </span>- <span class="nt">preference</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span><span class="c"># 其次选择 aws c5 的机器</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">node.kubernetes.io/instance-type</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.2xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.4xlarge&#34;</span><span class="w">
</span><span class="w">                </span>- <span class="s2">&#34;c5.9xlarge&#34;</span><span class="w">
</span><span class="w">            </span><span class="nt">weight</span><span class="p">:</span><span class="w"> </span><span class="m">60</span><span class="w">
</span><span class="w">         </span><span class="c"># 如果没 spot-group-c 可用，也可选择 ondemand-group-c 的节点跑</span><span class="w">
</span><span class="w">          </span><span class="nt">requiredDuringSchedulingIgnoredDuringExecution</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">nodeSelectorTerms</span><span class="p">:</span><span class="w">
</span><span class="w">            </span>- <span class="nt">matchExpressions</span><span class="p">:</span><span class="w">
</span><span class="w">              </span>- <span class="nt">key</span><span class="p">:</span><span class="w"> </span><span class="l">eks.amazonaws.com/nodegroup</span><span class="w">
</span><span class="w">                </span><span class="nt">operator</span><span class="p">:</span><span class="w"> </span><span class="l">In</span><span class="w">
</span><span class="w">                </span><span class="nt">values</span><span class="p">:</span><span class="w">
</span><span class="w">                </span>- <span class="l">spot-group-c</span><span class="w">
</span><span class="w">                </span>- <span class="l">ondemand-group-c</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="c"># ...</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="2-pod-anti-affinity">2. Pod Anti-Affinity</h3>
<p>It is generally recommended to configure Pod anti-affinity for each Deployment&rsquo;s template to break up Pods across all nodes.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh">apiVersion: apps/v1
kind: Deployment
metadata:
  name: xxx
  namespace: xxx
spec:
  <span class="c1"># ...</span>
  template:
    <span class="c1"># ...</span>
    spec:
      replicas: <span class="m">3</span>
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution: <span class="c1"># 非强制性条件</span>
          - weight: <span class="m">100</span>  <span class="c1"># weight 用于为节点评分，会优先选择评分最高的节点</span>
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - xxx
                - key: version
                  operator: In
                  values:
                  - v12
              <span class="c1"># 将 pod 尽量打散在多个可用区</span>
              topologyKey: topology.kubernetes.io/zone
          requiredDuringSchedulingIgnoredDuringExecution:  <span class="c1"># 强制性要求</span>
          <span class="c1"># 注意这个没有 weights，必须满足列表中的所有条件</span>
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - xxx
              - key: version
                operator: In
                values:
                - v12
            <span class="c1"># Pod 必须运行在不同的节点上</span>
            topologyKey: kubernetes.io/hostname

</code></pre></td></tr></table>
</div>
</div><h2 id="5-pods-ready-probe-live-probe-and-startup-probe">5. Pod&rsquo;s Ready Probe, Live Probe and Startup Probe</h2>
<p>Pods provide the following three probes, all of which support service availability probing using Command, HTTP API, and TCP Socket.</p>
<ul>
<li><code>startupProbe</code> Startup Probe (Kubernetes v1.18 [beta]): After this probe is passed, the &ldquo;Ready Probe&rdquo; and &ldquo;Survival Probe&rdquo; will perform the survivability and readiness checks
<ul>
<li>Used to perform survivability checks on slow-start containers to prevent them from being killed before they start running
<ul>
<li>startupProbe is obviously more flexible than livenessProbe&rsquo;s initialDelaySeconds parameter.</li>
<li>It also delays the readinessProbe from taking effect, mainly to avoid pointless probes. It is obviously impossible to be ready before the container is even startUp.</li>
</ul>
</li>
<li>The program will have at most <code>failureThreshold * periodSeconds</code> for start-up, for example, if <code>failureThreshold=20</code> and <code>periodSeconds=5</code> are set, the maximum program start-up time will be 100s, if more than 100s still do not pass the &ldquo;start-up probe&rdquo;, the container will be killed.</li>
</ul>
</li>
<li><code>readinessProbe</code> readiness probe:
<ul>
<li>If the number of failed readiness probes exceeds the <code>failureThreshold</code> limit (default three times), the service will be temporarily kicked out of the Service&rsquo;s Endpoints until the service meets the <code>successThreshold</code> again.</li>
</ul>
</li>
<li><code>livenessProbe</code> Survival Probe: detects if the service is alive, it can catch deadlocks and other conditions and kill such containers in time.
<ul>
<li>Possible reasons for the failure of the survivability probe.
<ul>
<li>The service is deadlocked and not responding to all requests</li>
<li>Service threads are all stuck waiting for external dependencies such as redis/mysql, resulting in unresponsive requests</li>
</ul>
</li>
<li>The container will be killed if the number of failed survival probes exceeds the <code>failureThreshold</code> limit (default three times), and then restarted according to the restart policy.
<ul>
<li><code>kubectl describe pod</code> will show the reboot reason as <code>State.Last State.Reason = Error, Exit Code=137</code> and Events will have <code>Liveness probe failed: ...</code> in Events.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The parameters of the above three types of probes are common, and the five time-related parameters are listed below.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="c"># 下面的值就是 k8s 的默认值</span><span class="w">
</span><span class="w"></span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">0</span><span class="w">  </span><span class="c"># 默认没有 delay 时间</span><span class="w">
</span><span class="w"></span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span><span class="w"></span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w"></span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w"></span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>Example.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c">#  ...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">xxx.com/app/my-app:v3</span><span class="w">
</span><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent </span><span class="w">
</span><span class="w">        </span><span class="c"># ... 省略若干配置</span><span class="w">
</span><span class="w">        </span><span class="nt">startupProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 直接使用健康检查接口即可</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">20</span><span class="w">  </span><span class="c"># 最多提供给服务 5s * 20 的启动时间</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># spring 的通用健康检查路径</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="c"># Readiness probes are very important for a RollingUpdate to work properly,</span><span class="w">
</span><span class="w">        </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># 简单起见可直接使用 livenessProbe 相同的接口，当然也可额外定义</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>Prior to Kubernetes 1.18, a common approach was to add a long <code>initialDelaySeconds</code> to the <code>ready probe</code> to achieve a similar function to the <code>start probe</code> to prevent containers from being restarted due to a slow start and failure of the survival probe. The example is as follows.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Deployment</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="c"># ...</span><span class="w">
</span><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c">#  ...</span><span class="w">
</span><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-app-v3</span><span class="w">
</span><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">xxx.com/app/my-app:v3</span><span class="w">
</span><span class="w">        </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent </span><span class="w">
</span><span class="w">        </span><span class="c"># ... 省略若干配置</span><span class="w">
</span><span class="w">        </span><span class="nt">livenessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health </span><span class="w"> </span><span class="c"># spring 的通用健康检查路径</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">120</span><span class="w">  </span><span class="c"># 前两分钟，都假设服务健康，避免 livenessProbe 失败导致服务重启</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">        </span><span class="c"># 容器一启动，Readiness probes 就会不断进行检测</span><span class="w">
</span><span class="w">        </span><span class="nt">readinessProbe</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">httpGet</span><span class="p">:</span><span class="w">
</span><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/actuator/health</span><span class="w">
</span><span class="w">            </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">8080</span><span class="w">
</span><span class="w">          </span><span class="nt">initialDelaySeconds</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">  </span><span class="c"># readiness probe 不需要设太长时间，使 Pod 尽快加入到 Endpoints.</span><span class="w">
</span><span class="w">          </span><span class="nt">periodSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">timeoutSeconds</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">          </span><span class="nt">failureThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">5</span><span class="w">
</span><span class="w">          </span><span class="nt">successThreshold</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h2 id="6-pod-security">6. Pod Security</h2>
<p>Only security-related parameters in Pods are described here. Other security policies, such as cluster-wide security policies, are not discussed here.</p>
<h3 id="1-pod-securitycontext">1. Pod SecurityContext</h3>
<p>By setting the Pod&rsquo;s SecurityContext, you can set a specific security policy for each Pod.</p>
<p>There are two types of SecurityContext.</p>
<ol>
<li>
<p><code>spec.securityContext</code> : This is a <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#podsecuritycontext-v1-core">PodSecurityContext</a> object</p>
<ul>
<li>As the name implies, it is valid for all contaienrs in the Pod.</li>
</ul>
</li>
<li>
<p><code>spec.containers[*].securityContext</code> : This is a <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.20/#securitycontext-v1-core">SecurityContext</a> object</p>
<ul>
<li>container&rsquo;s private SecurityContext</li>
</ul>
</li>
</ol>
<p>The parameters of these two SecurityContexts only partially overlap, with the overlapping part <code>spec.containers[*].securityContext</code> having higher priority.</p>
<p>Some of the more common security policies we encounter for <strong>elevating privileges</strong> are</p>
<ol>
<li>Privileged container: <code>spec.containers[*].securityContext.privileged</code></li>
<li>add (Capabilities) optional system-level capabilities: <code>spec.containers[*].securityContext.capabilities.add</code>.
<ol>
<li>Only a few containers, such as the ntp sync service, can enable this feature. Please note that this is very dangerous.</li>
</ol>
</li>
<li>Sysctls: system parameter: <code>spec.securityContext.sysctls</code></li>
</ol>
<p><strong>Permission Restrictions</strong> The relevant security policies are (<strong>It is highly recommended to configure the following security policies on all Pods on demand!</strong>).</p>
<ol>
<li><code>spec.volumes</code> : all data volumes can be set with read and write permissions</li>
<li><code>spec.securityContext.runAsNonRoot: true</code> Pods must be run as a non-root user</li>
<li><code>spec.containers[*].securityContext.readOnlyRootFileSystem:true</code> <strong>Set container level to read-only to prevent container files from being tampered with.</strong>
<ol>
<li>If the microservice needs to read and write files, it is recommended to mount additional data volumes of type <code>emptydir</code>.</li>
</ol>
</li>
<li><code>spec.containers[*].securityContext.allowPrivilegeEscalation: false</code> Do not allow Pod to do any privilege elevation!</li>
<li><code>spec.containers[*].securityContext.capabilities.drop</code> : removes (Capabilities) optional system-level capabilities</li>
</ol>
<p>There are other features such as specifying the running users/groups of containers that are not listed, so please refer to the Kubernetes documentation.</p>
<p>An example of a stateless microservice Pod configuration.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;Pod name&gt;</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">- name</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;container name&gt;</span><span class="w">
</span><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;image&gt;</span><span class="w">
</span><span class="w">    </span><span class="nt">imagePullPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">IfNotPresent </span><span class="w">
</span><span class="w">    </span><span class="c"># ......此处省略 500 字</span><span class="w">
</span><span class="w">    </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">      </span><span class="nt">readOnlyRootFilesystem</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># 将容器层设为只读，防止容器文件被篡改。</span><span class="w">
</span><span class="w">      </span><span class="nt">allowPrivilegeEscalation</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">  </span><span class="c"># 禁止 Pod 做任何权限提升</span><span class="w">
</span><span class="w">      </span><span class="nt">capabilities</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">drop</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="c"># 禁止容器使用 raw 套接字，通常只有 hacker 才会用到 raw 套接字。</span><span class="w">
</span><span class="w">        </span><span class="c"># raw_socket 可自定义网络层数据，避开 tcp/udp 协议栈，直接操作底层的 ip/icmp 数据包。可实现 ip 伪装、自定义协议等功能。</span><span class="w">
</span><span class="w">        </span><span class="c"># 去掉 net_raw 会导致 tcpdump 无法使用，无法进行容器内抓包。需要抓包时可临时去除这项配置</span><span class="w">
</span><span class="w">        </span>- <span class="l">NET_RAW</span><span class="w">
</span><span class="w">        </span><span class="c"># 更好的选择：直接禁用所有 capabilities</span><span class="w">
</span><span class="w">        </span><span class="c"># - ALL</span><span class="w">
</span><span class="w">  </span><span class="nt">securityContext</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="c"># runAsUser: 1000  # 设定用户</span><span class="w">
</span><span class="w">    </span><span class="c"># runAsGroup: 1000  # 设定用户组</span><span class="w">
</span><span class="w">    </span><span class="nt">runAsNonRoot</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">  </span><span class="c"># Pod 必须以非 root 用户运行</span><span class="w">
</span><span class="w">    </span><span class="nt">seccompProfile</span><span class="p">:</span><span class="w">  </span><span class="c"># security compute mode</span><span class="w">
</span><span class="w">      </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">RuntimeDefault</span><span class="w">
</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><h3 id="2-seccomp-security-compute-mode">2. seccomp: security compute mode</h3>
<p>seccomp and seccomp-bpf allow filtering of system calls, preventing user binaries from performing dangerous operations on host operating system components that are not normally needed. It is somewhat similar to Falco, but Seccomp does not provide special support for containers.</p>
<p>Video:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=Ro4QRx7VPsY&amp;list=PLj6h78yzYM2Pn8RxfLh2qrXBDftr6Qjut$index=22">Seccomp: What Can It Do For You? - Justin Cormack, Docker</a></li>
</ul>
<h2 id="other-issues">Other issues</h2>
<ul>
<li>Disparity in performance across node types, resulting in unbalanced CPU load with balanced QPS
<ul>
<li>Solution (not verified).
<ul>
<li>Try to use instance types with the same performance: add node type affinity via <code>podAffinity</code> and <code>nodeAffinity</code></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/k8s/">k8s</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/2022-01/kubernetes-deployemnt-using-kubeadm/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Deploy a Kubernetes cluster</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/2022-01/not-addressable-in-golang/">
            <span class="next-text nav-default">Understanding of non-addressability in Golang</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://www.sobyte.net/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021 - 
    2022<span class="heart"><i class="iconfont icon-heart"></i></span><span></span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c99b103c33d1539acf3025e1913697534542c4a5aa5af0ccc20475ed2863603b.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
